{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFVGnAoAemOz"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "5HwDlpcGiFxA",
    "outputId": "facb1f82-c8ec-4f1f-aaf8-1bd7c4eebada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "# kaggleの塩画像データを使いたいのでkaggleコマンドでダウンロード\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xxvS78ioiFuR",
    "outputId": "6ae082ca-5dcb-482b-9430-bc0780c513e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "s21L-OADoB7a",
    "outputId": "b061f69d-cb0f-4804-8cd3-58b4458c1a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "depths.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "flamingo.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Downloading competition_data.zip to /content\n",
      " 98% 213M/217M [00:01<00:00, 178MB/s]\n",
      "100% 217M/217M [00:01<00:00, 185MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions download -c tgs-salt-identification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bjKCRp0SkzYK",
    "outputId": "39e41d3a-1665-4ab6-9428-695b36bbc280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘train’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMXGT0NVk2hb"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/competition_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suiyZW7jpavo"
   },
   "outputs": [],
   "source": [
    "# rm -rf train/masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lKoIgVKr5Jz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3GIGU70iFsq"
   },
   "outputs": [],
   "source": [
    "!unzip /content/competition_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Er7Tep30r6mW"
   },
   "outputs": [],
   "source": [
    "# 移動に時間が掛かるので、フォルダを開いて空でも待つ\n",
    "!mv /content/competition_data/train/images/* /content/train/images\n",
    "!mv /content/competition_data/train/masks/* /content/train/masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aHtqxLt3mlLe",
    "outputId": "7f487be7-023c-4ec2-df08-5866c146fe18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGT5dm6E7Y-O"
   },
   "outputs": [],
   "source": [
    "!cp /content/competition_data/sample_submission.csv /content/sample_submission.csv\n",
    "!cp /content/competition_data/train.csv /content/train.csv\n",
    "!cp /content/competition_data/depths.csv /content/depths.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsksKTTK71TD"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAq5qLfZ71QP"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()  #trainのid,mask,depth情報\n",
    "    \n",
    "    #maskの含有率を整数クラスに置き換え\n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2)) #y画像のマスク面積の比率を算出してクラス分け\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "    print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):   #image_tensor= X_train_ch(4000,101,101,3)\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):  #0.01刻みのデータを生成\n",
    "        image_tensor[row, :, 1] = const                         #1chの各行に0.01刻みのデータを代入\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])   #2chに0ch*1chのデータを代入\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)   #行方向の隣り合う要素同士の差分を計算\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)   #列方向の隣り合う要素同士の差分を計算\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0) #単一色の境界を追加\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0) #単一色の境界を追加\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvTz-FIk8C8w"
   },
   "source": [
    "Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wR7KXp2Q71Nf",
    "outputId": "c52adf8b-8cac-4093-9164-ab56116800ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "            id                                           rle_mask\n",
      "0   2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n",
      "1   3cb59a4fdc                                             1 5656\n",
      "2   e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n",
      "3   c78c89577c                                              101 1\n",
      "4   6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n",
      "5   aae8971d6e  6664 3 6765 3 6866 3 6967 3 7068 3 7169 3 7267...\n",
      "6   b80db32c01                                                NaN\n",
      "7   164873b51f                                                NaN\n",
      "8   e335542c17  1 2828 2834 96 2936 95 3040 92 3142 91 3244 90...\n",
      "9   db840e1e22  505 1 605 2 705 3 805 4 905 5 1005 6 1106 6 12...\n",
      "10  a898892737  1 5655 5657 99 5758 97 5859 96 5960 94 6061 93...\n",
      "11  c33df3d7ad  1 6160 6162 97 6263 92 6364 88 6465 86 6566 82...\n",
      "12  b202b6b3d4  6460 5 6550 16 6646 21 6746 22 6846 23 6947 23...\n",
      "13  878566ab56  89 13 190 13 291 13 392 13 494 12 595 12 697 1...\n",
      "14  62e72fe39a                                                NaN\n",
      "15  e021227dbd                                                NaN\n",
      "16  dd580d1681  7677 6 7778 18 7879 31 7980 38 8081 50 8182 53...\n",
      "17  6fe2b681e4  8280 3 8381 3 8482 3 8583 3 8684 3 8785 3 8887...\n",
      "18  1bd1c8c771  76 26 176 27 276 28 376 29 476 30 575 32 673 3...\n",
      "19  5b28c5ba50  2506 20 2585 42 2672 56 2765 64 2863 67 2961 7...\n",
      "\n",
      "test:\n",
      "            id rle_mask\n",
      "0   3e06571ef3      1 1\n",
      "1   a51b08d882      1 1\n",
      "2   c32590b06f      1 1\n",
      "3   15f7a047c7      1 1\n",
      "4   e8827bc832      1 1\n",
      "5   d83fe9fa7a      1 1\n",
      "6   2de62031ee      1 1\n",
      "7   29cf979b92      1 1\n",
      "8   58ef954a94      1 1\n",
      "9   ccec631d75      1 1\n",
      "10  a93060eb0d      1 1\n",
      "11  09ef36d784      1 1\n",
      "12  e907b958e2      1 1\n",
      "13  a6f46b656e      1 1\n",
      "14  1819f215f7      1 1\n",
      "15  0291a0c49b      1 1\n",
      "16  16fb21800b      1 1\n",
      "17  07a70fdbf3      1 1\n",
      "18  ab89a9e4e5      1 1\n",
      "19  3648353086      1 1\n",
      "depths:\n",
      "            id    z\n",
      "0   4ac19fb269  306\n",
      "1   1825fadf99  157\n",
      "2   f59821d067  305\n",
      "3   5b435fad9d  503\n",
      "4   e340e7bfca  783\n",
      "5   2ffea0c397  429\n",
      "6   6cf284fb9e  600\n",
      "7   d0244d6c38   51\n",
      "8   cffbfab33b  755\n",
      "9   e82421363e   68\n",
      "10  9090f8f97b  253\n",
      "11  778a92f420  476\n",
      "12  57e394bc67  765\n",
      "13  1efe1909ed  143\n",
      "14  8d89d465fc  529\n",
      "15  211fc910da  336\n",
      "16  b12a5a2b61  475\n",
      "17  28948eeb9c  306\n",
      "18  28f6f52c8f  317\n",
      "19  211eb21702  188\n",
      "\n",
      "            id                                           rle_mask    z\n",
      "0   2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312\n",
      "1   3cb59a4fdc                                             1 5656  603\n",
      "2   e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687\n",
      "3   c78c89577c                                              101 1  236\n",
      "4   6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805\n",
      "5   aae8971d6e  6664 3 6765 3 6866 3 6967 3 7068 3 7169 3 7267...  231\n",
      "6   b80db32c01                                                NaN  704\n",
      "7   164873b51f                                                NaN  162\n",
      "8   e335542c17  1 2828 2834 96 2936 95 3040 92 3142 91 3244 90...  505\n",
      "9   db840e1e22  505 1 605 2 705 3 805 4 905 5 1005 6 1106 6 12...  493\n",
      "10  a898892737  1 5655 5657 99 5758 97 5859 96 5960 94 6061 93...  620\n",
      "11  c33df3d7ad  1 6160 6162 97 6263 92 6364 88 6465 86 6566 82...  648\n",
      "12  b202b6b3d4  6460 5 6550 16 6646 21 6746 22 6846 23 6947 23...  511\n",
      "13  878566ab56  89 13 190 13 291 13 392 13 494 12 595 12 697 1...  129\n",
      "14  62e72fe39a                                                NaN  154\n",
      "15  e021227dbd                                                NaN  281\n",
      "16  dd580d1681  7677 6 7778 18 7879 31 7980 38 8081 50 8182 53...  765\n",
      "17  6fe2b681e4  8280 3 8381 3 8482 3 8583 3 8684 3 8785 3 8887...  230\n",
      "18  1bd1c8c771  76 26 176 27 276 28 376 29 476 30 575 32 673 3...  441\n",
      "19  5b28c5ba50  2506 20 2585 42 2672 56 2765 64 2863 67 2961 7...  610\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/content/train.csv\")\n",
    "test = pd.read_csv(\"/content/sample_submission.csv\")\n",
    "depth = pd.read_csv(\"/content/depths.csv\")\n",
    "\n",
    "train_src = '/content/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head(20)))\n",
    "print('\\ntest:\\n{}'.format(test.head(20)))\n",
    "print('depths:\\n{}'.format(depth.head(20)))\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFFHiFaE8O2L"
   },
   "source": [
    "Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FjDITOp671LG",
    "outputId": "8239ad56-dc2c-447e-bf41-abdbf4ed0953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "#画像をグレースケールで読み込んでndarray配列に参照コピーし、０〜１のデータにならす。\n",
    "X_train = np.asarray(\n",
    "    [cv2.imread('/content/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('/content/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape) #101x101x1チャンネルの画像4000枚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "QyLrU-n971Jh",
    "outputId": "5e71537b-a7ff-42ac-b54b-221aad4ac2c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa175b86c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFSCAYAAAAJl+KKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#変換した画像をランダムに表示してみる\n",
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z14YYDDx8f-I"
   },
   "source": [
    "Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "R5q8qi8f71G0",
    "outputId": "c90dc8e2-2a76-4dfc-cc18-6828b7323523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id                                           rle_mask    z  \\\n",
      "0     2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312   \n",
      "1     3cb59a4fdc                                             1 5656  603   \n",
      "2     e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687   \n",
      "3     c78c89577c                                              101 1  236   \n",
      "4     6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805   \n",
      "...          ...                                                ...  ...   \n",
      "3995  429b289e07  1 6463 6465 98 6566 97 6667 95 6768 94 6869 93...  562   \n",
      "3996  5d752d6d4a                                                NaN  235   \n",
      "3997  26527458de                                                NaN  587   \n",
      "3998  25fb3a895a                                                NaN  468   \n",
      "3999  f30c36bf6b                                                NaN  324   \n",
      "\n",
      "      coverage  coverage_class  \n",
      "0     0.530928               6  \n",
      "1     0.554455               6  \n",
      "2     0.481717               5  \n",
      "3     0.000098               1  \n",
      "4     0.078718               1  \n",
      "...        ...             ...  \n",
      "3995  0.890991               9  \n",
      "3996  0.000000               0  \n",
      "3997  0.000000               0  \n",
      "3998  0.000000               0  \n",
      "3999  0.000000               0  \n",
      "\n",
      "[4000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5Gjte5nz71ER",
    "outputId": "1501a83b-c0ac-4a77-b0ba-c56c660ae850"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2c45b152f1', '3cb59a4fdc', 'e185ab5dc1', ..., '26527458de',\n",
       "       '25fb3a895a', 'f30c36bf6b'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q68JAVUx71Cv",
    "outputId": "a1e8966d-b857-4e71-a981-810c63b03061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.coverage_class.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zX4rLw0f8qgn"
   },
   "source": [
    "Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "O78Ok1r_71AZ",
    "outputId": "d752abb6-cb8a-4d16-b23a-ee5f3c95f051"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337) #データセットを５つに分割\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1) #(4000,101,101,1)>(4000,101,101,3)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))  #2chを特徴量エンジニアリング\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "#print(X_resized[0:3])\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):  #split(X, y)\n",
    "    #train_index: trainデータのインデックス情報\n",
    "    #y画像を数値化したもの（coverage_class）をyラベルとして代用している（0~10の多クラスとして擬似的に扱う）\n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "\n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSQBT8uY8zNm"
   },
   "source": [
    "Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Or4vtPSP70-h"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmpZ3LRl86gL"
   },
   "source": [
    "### ResNet50で学習・推定\n",
    "\n",
    "Encoder features - ResNet50:\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers. Default input size will be assumed, which is (224, 224, 3). Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call K.clear_session()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Fxi_XSnn7065",
    "outputId": "c095f5d3-8140-469b-f273-4da156ba8eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgyoICh086cI"
   },
   "source": [
    "### Decoder blocks:\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed. For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VFBoBXB704V"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])   #入力のリスト同士を足し合わせる\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr4yqcsk86W7"
   },
   "source": [
    "#### Model definition:\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miAno42C702d"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output   #(None, 112, 112, 64)\n",
    "    encoder2 = base_model.get_layer('activation_10').output #(None, 56, 56, 256)\n",
    "    encoder3 = base_model.get_layer('activation_22').output #(None, 28, 28, 512) \n",
    "    encoder4 = base_model.get_layer('activation_40').output #(None, 14, 14, 1024)\n",
    "    encoder5 = base_model.get_layer('activation_49').output #(None, 7, 7, 2048)\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)  #(None, 7, 7, 512)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256) #(None, 7, 7, 256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(None, 14, 14, 1280)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128) #(None, 14, 14, 128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) #(None, 28, 28, 640)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64) #(None, 28, 28, 64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1) #(None, 56, 56, 320)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64) #(None, 56, 56, 64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1) #(None, 112, 112, 128)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1) #(None, 224, 224, 128)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32) #(None, 224, 224, 32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)  #(None, 224, 224, 1)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oW6ax54c9jIa"
   },
   "source": [
    "#### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LmDZgIlw70zb",
    "outputId": "a74cb596-2886-45b4-bc9a-12cff0b10631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-14-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwTOJ1LS9q6A"
   },
   "source": [
    "#### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "G1zrjC8hrPFq",
    "outputId": "9b3966fd-d4aa-45cb-dbe6-7d014bcf3155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3)\n",
      "(3200, 224, 224, 1)\n",
      "(800, 224, 224, 3)\n",
      "(800, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MtcZti6p70xO",
    "outputId": "bc9a41d3-aba8-490a-acda-da3fabf5b7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 10 samples, validate on 4 samples\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 46s 5s/step - loss: 1.3218 - my_iou_metric: 0.0700 - val_loss: 4.9027 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "# データ量が多いので減らす\n",
    "X_tr = X_tr[:10]\n",
    "y_tr = y_tr[:10]\n",
    "\n",
    "X_val = X_val[:4]\n",
    "y_val = y_val[:4]\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8XJzU9Q92g0"
   },
   "source": [
    "Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYBbJaJQ70u9"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXi_mV90-Ay4"
   },
   "source": [
    "Threshold optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-YGjmne70s9"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qrexZ94370rW",
    "outputId": "c8203129-5535-453d-861d-51886bc36f09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:44<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "sgLCT6Nq70oZ",
    "outputId": "6c21a357-3b36-425a-c512-66924b7b3605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3258 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.215954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.050660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.179125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.189375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.252250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.325750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.215954\n",
       "std     0.204939   0.050660\n",
       "min     0.200000   0.162000\n",
       "25%     0.370000   0.179125\n",
       "50%     0.540000   0.189375\n",
       "75%     0.710000   0.252250\n",
       "max     0.880000   0.325750"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "BRlHFvZD70lf",
    "outputId": "9d4eced4-27a1-4cda-dc17-f559908c158f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa15d498c18>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIWCAYAAACoQ2BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04feR7XW-x_W"
   },
   "source": [
    "#### 【問題1】コードレビュー\n",
    "- 画像についての特徴量エンジニアリングを行なっている。具体的には、深度情報を擬似的に付加して学習させることで、スコアを若干改善している\n",
    "- trainデータ分割のところで、yラベルを擬似的にクラス分けして、データが適切に分割されるよう調整している。\n",
    "- 転移学習では、重みの固定は行わず、初期値として利用している。ImageNETの画像と地震探査画像が大きく異なる点がその理由と考えられる。\n",
    "- UnetのDeConvolutionでは、プーリング前のデータを使用することで、特徴量情報をlossさせない工夫をしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohMHTgJt-4WN"
   },
   "source": [
    "#### 【問題2】コードの書き換え\n",
    "VGGで学習・推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "xPjeCgUI-vaU",
    "outputId": "10a3bc88-54a8-48ed-8007-1af98a77fe17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 12,979,200\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "for layer in base_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EvOkYx9-vYY"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output #(None, 224, 224, 64)\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output #(None, 112, 112, 128) \n",
    "    encoder3 = base_model.get_layer('block3_conv3').output  #(None, 56, 56, 256)\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output  #(None, 28, 28, 512) \n",
    "    encoder5 = base_model.get_layer('block5_conv3').output  #(None, 14, 14, 512)\n",
    "    encoder6 = base_model.get_layer('block5_pool').output #(None, 7, 7, 512)\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder6, 'center', num_filters=128)\n",
    "    concat6 = concatenate([center, encoder6], axis=-1) #(None, 7, 7, 640)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder5 = decoder_block(\n",
    "        concat6, 'decoder5', num_filters=64) #(None, 7, 7, 256)\n",
    "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1) #(None, 14, 14, 576)\n",
    "\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=64) #(None, 14, 14, 64) \n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(None, 28, 28, 576)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=32) #(None, 28, 28, 32)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) #(None, 56, 56, 288)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=16) #(None, 56, 56, 16)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1) #(None, 112, 112, 144)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=8) # (None, 112, 112, 8)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1) #(None, 224, 224, 72)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    #output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H9pnBFQD-vWY",
    "outputId": "1d1e7671-50c9-40e6-860d-11f6cdf4cfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 128)    589952      block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 128)    512         center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 128)    6272        center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 640)    0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv (Conv2D)          (None, 7, 7, 64)     368704      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn (BatchNormalization (None, 7, 7, 64)     256         decoder5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation (PReLU)     (None, 7, 7, 64)     3136        decoder5_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 64)   0           decoder5_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 576)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 64)   331840      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 64)   256         decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 14, 14, 64)   12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 64)   0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 576)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 32)   165920      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 32)   128         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 32)   25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 32)   0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 288)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 16)   41488       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 16)   64          decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 16)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 16) 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 144 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 112, 112, 8)  10376       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 112, 112, 8)  32          decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 112, 112, 8)  100352      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 8)  0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 72) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 20768       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 18,048,345\n",
      "Trainable params: 18,047,657\n",
      "Non-trainable params: 688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#inspect created model\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "for layer in base_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aD24I6nR_0oJ"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c2jP8LcW-vUX",
    "outputId": "d2809e38-1117-48a7-caae-6be1e890cd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 128)    589952      block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 128)    512         center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 128)    6272        center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 128)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 64)     73792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 64)     256         center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 64)     3136        center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 64)     0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 128)    73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 128)    512         center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 128)    6272        center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 128)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 128)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 640)    0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv1 (Conv2D)         (None, 7, 7, 64)     368704      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 64)     256         decoder5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation1 (PReLU)    (None, 7, 7, 64)     3136        decoder5_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 64)     0           decoder5_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv2 (Conv2D)         (None, 7, 7, 32)     18464       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 32)     128         decoder5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation2 (PReLU)    (None, 7, 7, 32)     1568        decoder5_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 32)     0           decoder5_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv3 (Conv2D)         (None, 7, 7, 64)     18496       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 64)     256         decoder5_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation3 (PReLU)    (None, 7, 7, 64)     3136        decoder5_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 64)     0           decoder5_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 64)     0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 576)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 64)   331840      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 64)   256         decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 64)   12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 64)   0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 32)   128         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 32)   6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 32)   0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 64)   18496       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 64)   256         decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 64)   12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 64)   0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 64)   0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 576)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 32)   165920      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 32)   128         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 32)   25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 32)   0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 16)   4624        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 16)   64          decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 16)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 16)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 32)   4640        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 32)   128         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 32)   25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 32)   0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 32)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 288)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 16)   41488       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 16)   64          decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 16)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 16)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 8)    1160        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 8)    32          decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 8)    25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 8)    0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 16)   1168        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 16)   64          decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 16)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 16)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 16)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 16) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 144 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 8)  10376       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 8)  32          decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 8)  100352      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 112, 112, 8)  0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 4)  292         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 4)  16          decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 4)  50176       decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 112, 112, 4)  0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 8)  296         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 8)  32          decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 8)  100352      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 112, 112, 8)  0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 112, 112, 8)  0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 8)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 72) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 20768       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 224, 224, 32) 0           dropout_19[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,998,221\n",
      "Trainable params: 20,996,501\n",
      "Non-trainable params: 1,720\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 10 samples, validate on 4 samples\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 41s 4s/step - loss: 2.0735 - my_iou_metric: 0.0000e+00 - val_loss: 1.6356 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_vgg.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAEaNOeu_8Fb"
   },
   "source": [
    "Validation set prediction and resizing to original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFqGS6it-vSU"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXv1fQZr__rT"
   },
   "source": [
    "Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYl5RlWx-vOJ"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zj6b16DK-vMD",
    "outputId": "b203bc56-fc9c-4498-9292-ba9ef6fc2e1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 142.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "udar_3o2-vJM",
    "outputId": "8989de0e-91dd-49d3-b3fe-1c6eeb39a374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.0250 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.006429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.011086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.006429\n",
       "std     0.204939   0.011086\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.000000\n",
       "50%     0.540000   0.000000\n",
       "75%     0.710000   0.012500\n",
       "max     0.880000   0.025000"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "M0PO1aRG-vHI",
    "outputId": "95def278-13eb-4f0a-bb62-bd8b57541d27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa16e952f98>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcMyEXqTAMuK"
   },
   "source": [
    "#### 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。ResNet50とVGGの結果比較\n",
    "- ResNet50の方がスコアが良い（より豊かな表現に対応できる？）\n",
    "- 処理速度についてはVGGの方がやや速いぐらい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzX-Cflp-vEq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJDfEKNVhwaM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20200325_sprint20_segmentation2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
