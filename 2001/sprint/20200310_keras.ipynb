{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sprint ディープラーニングフレームワーク２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7786, 0.5922, 0.7409],\n",
      "        [0.8320, 0.4117, 0.8428],\n",
      "        [0.1961, 0.1453, 0.9069],\n",
      "        [0.4553, 0.5752, 0.3921],\n",
      "        [0.2258, 0.4074, 0.7267]])\n"
     ]
    }
   ],
   "source": [
    "#pytorchをインポート\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】公式Exampleを分担して実行\n",
    "やり方：リンクをクリック→GitHubのREADMEのリンクに飛ぶ\n",
    "→左側から好きな物を選ぶ（例：初級→KerasによるMLの基本→基本的な画像分類）\n",
    "→コードを全部コピーして最後まで流す→結果を学習共有時に共有\n",
    "\n",
    "映画レビューのテキスト分類{こちらを発表} https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "ファッションMNIST https://www.tensorflow.org/tutorials/keras/basic_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】Iris（2値分類）をKerasで学習\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research\n",
    "\n",
    "https://github.com/google-research/google-research\n",
    "\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。\n",
    "\n",
    "### 3.異なるフレームワークへの書き換え\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n",
    "\n",
    "#### Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0310 13:17:12.428389 140735937377216 deprecation.py:506] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0310 13:17:12.540295 140735937377216 deprecation.py:323] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.7360 - acc: 0.5125\n",
      "Epoch 2/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.7100 - acc: 0.4375\n",
      "Epoch 3/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6936 - acc: 0.5125\n",
      "Epoch 4/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6544 - acc: 0.6250\n",
      "Epoch 5/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6453 - acc: 0.6375\n",
      "Epoch 6/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6210 - acc: 0.6375\n",
      "Epoch 7/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6185 - acc: 0.6250\n",
      "Epoch 8/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6091 - acc: 0.6875\n",
      "Epoch 9/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5694 - acc: 0.7750\n",
      "Epoch 10/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5395 - acc: 0.8625\n",
      "Epoch 11/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5462 - acc: 0.8000\n",
      "Epoch 12/150\n",
      "80/80 [==============================] - 0s 985us/sample - loss: 0.5263 - acc: 0.8625\n",
      "Epoch 13/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5173 - acc: 0.8500\n",
      "Epoch 14/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4915 - acc: 0.9250\n",
      "Epoch 15/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4875 - acc: 0.8750\n",
      "Epoch 16/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4828 - acc: 0.9000\n",
      "Epoch 17/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4627 - acc: 0.9250\n",
      "Epoch 18/150\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.4479 - acc: 0.9125\n",
      "Epoch 19/150\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.4395 - acc: 0.9125\n",
      "Epoch 20/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4320 - acc: 0.9250\n",
      "Epoch 21/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4137 - acc: 0.9250\n",
      "Epoch 22/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4149 - acc: 0.9250\n",
      "Epoch 23/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4186 - acc: 0.9000\n",
      "Epoch 24/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3915 - acc: 0.9000\n",
      "Epoch 25/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3822 - acc: 0.9125\n",
      "Epoch 26/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3815 - acc: 0.9250\n",
      "Epoch 27/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3786 - acc: 0.9250\n",
      "Epoch 28/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3617 - acc: 0.9125\n",
      "Epoch 29/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3706 - acc: 0.8750\n",
      "Epoch 30/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3535 - acc: 0.9250\n",
      "Epoch 31/150\n",
      "80/80 [==============================] - 0s 973us/sample - loss: 0.3419 - acc: 0.9500\n",
      "Epoch 32/150\n",
      "80/80 [==============================] - 0s 847us/sample - loss: 0.3354 - acc: 0.9375\n",
      "Epoch 33/150\n",
      "80/80 [==============================] - 0s 981us/sample - loss: 0.3333 - acc: 0.9375\n",
      "Epoch 34/150\n",
      "80/80 [==============================] - 0s 932us/sample - loss: 0.3305 - acc: 0.9000\n",
      "Epoch 35/150\n",
      "80/80 [==============================] - 0s 904us/sample - loss: 0.3110 - acc: 0.9500\n",
      "Epoch 36/150\n",
      "80/80 [==============================] - 0s 925us/sample - loss: 0.3080 - acc: 0.9625\n",
      "Epoch 37/150\n",
      "80/80 [==============================] - 0s 997us/sample - loss: 0.3133 - acc: 0.9500\n",
      "Epoch 38/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3069 - acc: 0.9500\n",
      "Epoch 39/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3036 - acc: 0.9500\n",
      "Epoch 40/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2925 - acc: 0.9500\n",
      "Epoch 41/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2908 - acc: 0.9250\n",
      "Epoch 42/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2983 - acc: 0.9375\n",
      "Epoch 43/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2758 - acc: 0.9625\n",
      "Epoch 44/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2701 - acc: 0.9750\n",
      "Epoch 45/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2828 - acc: 0.9500\n",
      "Epoch 46/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2679 - acc: 0.9500\n",
      "Epoch 47/150\n",
      "80/80 [==============================] - 0s 975us/sample - loss: 0.2716 - acc: 0.9250\n",
      "Epoch 48/150\n",
      "80/80 [==============================] - 0s 981us/sample - loss: 0.2635 - acc: 0.9375\n",
      "Epoch 49/150\n",
      "80/80 [==============================] - 0s 978us/sample - loss: 0.2681 - acc: 0.9250\n",
      "Epoch 50/150\n",
      "80/80 [==============================] - 0s 892us/sample - loss: 0.2533 - acc: 0.9500\n",
      "Epoch 51/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2486 - acc: 0.9500\n",
      "Epoch 52/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2512 - acc: 0.9250\n",
      "Epoch 53/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2355 - acc: 0.9500\n",
      "Epoch 54/150\n",
      "80/80 [==============================] - 0s 915us/sample - loss: 0.2475 - acc: 0.9500\n",
      "Epoch 55/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2344 - acc: 0.9500\n",
      "Epoch 56/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2317 - acc: 0.9500\n",
      "Epoch 57/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2254 - acc: 0.9500\n",
      "Epoch 58/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2341 - acc: 0.9250\n",
      "Epoch 59/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2199 - acc: 0.9500\n",
      "Epoch 60/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2221 - acc: 0.9500\n",
      "Epoch 61/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2194 - acc: 0.9625\n",
      "Epoch 62/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2242 - acc: 0.9250\n",
      "Epoch 63/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1969 - acc: 0.9500\n",
      "Epoch 64/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2219 - acc: 0.9500\n",
      "Epoch 65/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2057 - acc: 0.9500\n",
      "Epoch 66/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2108 - acc: 0.9625\n",
      "Epoch 67/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2094 - acc: 0.9375\n",
      "Epoch 68/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2040 - acc: 0.9500\n",
      "Epoch 69/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2112 - acc: 0.9500\n",
      "Epoch 70/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1914 - acc: 0.9750\n",
      "Epoch 71/150\n",
      "80/80 [==============================] - 0s 987us/sample - loss: 0.1960 - acc: 0.9625\n",
      "Epoch 72/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2102 - acc: 0.9500\n",
      "Epoch 73/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2019 - acc: 0.9500\n",
      "Epoch 74/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1961 - acc: 0.9500\n",
      "Epoch 75/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1893 - acc: 0.9500\n",
      "Epoch 76/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1868 - acc: 0.9750\n",
      "Epoch 77/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1772 - acc: 0.9625\n",
      "Epoch 78/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1955 - acc: 0.9625\n",
      "Epoch 79/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1890 - acc: 0.9625\n",
      "Epoch 80/150\n",
      "80/80 [==============================] - 0s 988us/sample - loss: 0.1790 - acc: 0.9625\n",
      "Epoch 81/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1764 - acc: 0.9750\n",
      "Epoch 82/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1814 - acc: 0.9625\n",
      "Epoch 83/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1801 - acc: 0.9625\n",
      "Epoch 84/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1736 - acc: 0.9750\n",
      "Epoch 85/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1818 - acc: 0.9500\n",
      "Epoch 86/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1735 - acc: 0.9500\n",
      "Epoch 87/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1716 - acc: 0.9750\n",
      "Epoch 88/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1759 - acc: 0.9750\n",
      "Epoch 89/150\n",
      "80/80 [==============================] - 0s 972us/sample - loss: 0.1689 - acc: 0.9500\n",
      "Epoch 90/150\n",
      "80/80 [==============================] - 0s 900us/sample - loss: 0.1689 - acc: 0.9625\n",
      "Epoch 91/150\n",
      "80/80 [==============================] - 0s 977us/sample - loss: 0.1690 - acc: 0.9500\n",
      "Epoch 92/150\n",
      "80/80 [==============================] - 0s 983us/sample - loss: 0.1655 - acc: 0.9625\n",
      "Epoch 93/150\n",
      "80/80 [==============================] - 0s 990us/sample - loss: 0.1676 - acc: 0.9500\n",
      "Epoch 94/150\n",
      "80/80 [==============================] - 0s 993us/sample - loss: 0.1598 - acc: 0.9750\n",
      "Epoch 95/150\n",
      "80/80 [==============================] - 0s 951us/sample - loss: 0.1651 - acc: 0.9500\n",
      "Epoch 96/150\n",
      "80/80 [==============================] - 0s 998us/sample - loss: 0.1593 - acc: 0.9500\n",
      "Epoch 97/150\n",
      "80/80 [==============================] - 0s 956us/sample - loss: 0.1619 - acc: 0.9750\n",
      "Epoch 98/150\n",
      "80/80 [==============================] - 0s 983us/sample - loss: 0.1521 - acc: 0.9750\n",
      "Epoch 99/150\n",
      "80/80 [==============================] - 0s 941us/sample - loss: 0.1586 - acc: 0.9625\n",
      "Epoch 100/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1523 - acc: 0.9625\n",
      "Epoch 101/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1448 - acc: 0.9750\n",
      "Epoch 102/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1522 - acc: 0.9875\n",
      "Epoch 103/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1555 - acc: 0.9500\n",
      "Epoch 104/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1495 - acc: 0.9750\n",
      "Epoch 105/150\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.1538 - acc: 0.9625\n",
      "Epoch 106/150\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.1538 - acc: 0.9750\n",
      "Epoch 107/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1462 - acc: 0.9625\n",
      "Epoch 108/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1520 - acc: 0.9500\n",
      "Epoch 109/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1380 - acc: 0.9625\n",
      "Epoch 110/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1523 - acc: 0.9625\n",
      "Epoch 111/150\n",
      "80/80 [==============================] - 0s 952us/sample - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 112/150\n",
      "80/80 [==============================] - 0s 951us/sample - loss: 0.1436 - acc: 0.9625\n",
      "Epoch 113/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1447 - acc: 0.9750\n",
      "Epoch 114/150\n",
      "80/80 [==============================] - 0s 977us/sample - loss: 0.1435 - acc: 0.9500\n",
      "Epoch 115/150\n",
      "80/80 [==============================] - 0s 961us/sample - loss: 0.1346 - acc: 0.9750\n",
      "Epoch 116/150\n",
      "80/80 [==============================] - 0s 970us/sample - loss: 0.1432 - acc: 0.9625\n",
      "Epoch 117/150\n",
      "80/80 [==============================] - 0s 955us/sample - loss: 0.1376 - acc: 0.9500\n",
      "Epoch 118/150\n",
      "80/80 [==============================] - 0s 934us/sample - loss: 0.1445 - acc: 0.9500\n",
      "Epoch 119/150\n",
      "80/80 [==============================] - 0s 983us/sample - loss: 0.1359 - acc: 0.9625\n",
      "Epoch 120/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1402 - acc: 0.9500\n",
      "Epoch 121/150\n",
      "80/80 [==============================] - 0s 936us/sample - loss: 0.1362 - acc: 0.9500\n",
      "Epoch 122/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1361 - acc: 0.9500\n",
      "Epoch 123/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1349 - acc: 0.9625\n",
      "Epoch 124/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1333 - acc: 0.9625\n",
      "Epoch 125/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1393 - acc: 0.9500\n",
      "Epoch 126/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1273 - acc: 0.9625\n",
      "Epoch 127/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1311 - acc: 0.9625\n",
      "Epoch 128/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1312 - acc: 0.9625\n",
      "Epoch 129/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1269 - acc: 0.9625\n",
      "Epoch 130/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1297 - acc: 0.9625\n",
      "Epoch 131/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1350 - acc: 0.9500\n",
      "Epoch 132/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1276 - acc: 0.9625\n",
      "Epoch 133/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1261 - acc: 0.9625\n",
      "Epoch 134/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1288 - acc: 0.9500\n",
      "Epoch 135/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1252 - acc: 0.9625\n",
      "Epoch 136/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1264 - acc: 0.9625\n",
      "Epoch 137/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1383 - acc: 0.9625\n",
      "Epoch 138/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1264 - acc: 0.9500\n",
      "Epoch 139/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1320 - acc: 0.9375\n",
      "Epoch 140/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1370 - acc: 0.9625\n",
      "Epoch 141/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1253 - acc: 0.9625\n",
      "Epoch 142/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1255 - acc: 0.9750\n",
      "Epoch 143/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1282 - acc: 0.9875\n",
      "Epoch 144/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1152 - acc: 0.9750\n",
      "Epoch 145/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1230 - acc: 0.9625\n",
      "Epoch 146/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1205 - acc: 0.9500\n",
      "Epoch 147/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1167 - acc: 0.9750\n",
      "Epoch 148/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1240 - acc: 0.9625\n",
      "Epoch 149/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1153 - acc: 0.9625\n",
      "Epoch 150/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1198 - acc: 0.9625\n",
      "y_pred_proba [0.12256274 0.99540675 0.10659918 0.99622154 0.8822733  0.9957762\n",
      " 0.2574502  0.86286926 0.99631023 0.986868   0.9578939  0.9763653\n",
      " 0.99440074 0.17484841 0.00961164 0.02926999 0.6363319  0.0243279\n",
      " 0.82435364 0.04060128]\n",
      "y_pred [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
      "y_test [[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Train loss: 0.11320356130599976\n",
      "Train accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "# ANDゲートの学習データを用意\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(4,))])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=150,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0310 13:17:48.371927 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0310 13:17:48.373934 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0310 13:17:48.381123 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 0.9750 - acc: 0.5333\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.5687 - acc: 0.7500\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.3967 - acc: 0.8583\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2780 - acc: 0.8750\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.3000 - acc: 0.8917\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1658 - acc: 0.9417\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2646 - acc: 0.9000\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1675 - acc: 0.9250\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 0.1302 - acc: 0.9417\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1719 - acc: 0.9333\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 0.1456 - acc: 0.9417\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2260 - acc: 0.9000\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2293 - acc: 0.9000\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1888 - acc: 0.9333\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1121 - acc: 0.9333\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2329 - acc: 0.9250\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1393 - acc: 0.9500\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1149 - acc: 0.9500\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1295 - acc: 0.9333\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 0.1243 - acc: 0.9583\n",
      "y_pred_proba [[4.8676308e-02 9.5132375e-01 1.8165684e-16]\n",
      " [9.9756539e-01 2.0254692e-03 4.0924834e-04]\n",
      " [1.1070637e-03 2.0700626e-09 9.9889296e-01]\n",
      " [6.5078676e-02 9.3492132e-01 1.3700827e-15]\n",
      " [2.1170538e-03 1.1551601e-08 9.9788290e-01]\n",
      " [3.0243160e-02 9.6975684e-01 2.9709881e-18]\n",
      " [2.1324928e-03 1.1776445e-08 9.9786747e-01]\n",
      " [9.9479455e-01 5.2000098e-03 5.4012139e-06]\n",
      " [9.9279660e-01 7.2018420e-03 1.5058912e-06]\n",
      " [9.9767071e-01 1.8274448e-03 5.0178729e-04]\n",
      " [5.4995966e-01 4.5004040e-01 8.1551044e-11]\n",
      " [9.9631447e-01 3.6538583e-03 3.1664207e-05]\n",
      " [9.9543178e-01 4.5403959e-03 2.7867043e-05]\n",
      " [9.8993671e-01 1.0061916e-02 1.2586753e-06]\n",
      " [9.9172956e-01 8.2658352e-03 4.5826546e-06]\n",
      " [2.1807898e-03 1.2497324e-08 9.9781919e-01]\n",
      " [9.9049699e-01 9.4989222e-03 4.1446219e-06]\n",
      " [9.9379808e-01 6.1612236e-03 4.0621770e-05]\n",
      " [3.0308045e-03 2.9931481e-08 9.9696916e-01]\n",
      " [1.6516092e-03 5.9792757e-09 9.9834836e-01]\n",
      " [1.2140390e-01 8.7859613e-01 4.9994373e-13]\n",
      " [9.8896468e-01 1.1028448e-02 6.8029385e-06]\n",
      " [2.9184597e-03 2.7076247e-08 9.9708146e-01]\n",
      " [3.5200447e-03 4.4530683e-08 9.9647993e-01]\n",
      " [7.2375745e-01 2.7624255e-01 5.5987687e-10]\n",
      " [1.9959093e-03 9.8799990e-09 9.9800414e-01]\n",
      " [2.7695270e-03 2.3562167e-08 9.9723047e-01]\n",
      " [9.9741298e-01 2.4206063e-03 1.6649226e-04]\n",
      " [9.6037549e-01 9.1071229e-04 3.8713753e-02]\n",
      " [2.9372787e-03 2.7542120e-08 9.9706274e-01]]\n",
      "y_pred [1 0 2 1 2 1 2 0 0 0 0 0 0 0 0 2 0 0 2 2 1 0 2 2 0 2 2 0 0 2]\n",
      "y_test [1 0 2 1 2 1 2 0 0 0 1 0 0 0 0 2 0 0 2 2 1 0 2 2 1 2 2 0 0 2]\n",
      "Train loss: 0.08341396600008011\n",
      "Train accuracy: 0.93333334\n"
     ]
    }
   ],
   "source": [
    "#セッションクリア\n",
    "K.clear_session()\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"../../dic_ml_ans/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "y = y.astype(np.int)#[:, np.newaxis]\n",
    "#print(y.shape)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# # さらにtrainとvalに分割\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# yをone-hot表現に変換\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "#y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "#print(y_train_one_hot.shape)\n",
    "\n",
    "# Functional API 4層のニューラルネットワーク\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(X)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy']) #多値分類なのでカテゴリカルクロスエントロピー\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)#[:, 0]\n",
    "\n",
    "# 最大値のインデックスで推定値を求める\n",
    "y_pred = np.argmax(y_pred_proba,axis=1)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0310 13:20:21.333909 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0310 13:20:21.336937 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0310 13:20:21.384109 140735937377216 deprecation_wrapper.py:119] From /Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test(292, 2)\n",
      "X_train(934, 2)\n",
      "y_train(934, 1)\n",
      "X_val(934, 2)\n",
      "y_val(234, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 71.0499 - mean_squared_error: 71.0499\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 1s 781us/step - loss: 7.4344 - mean_squared_error: 7.4344\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 1s 755us/step - loss: 0.2461 - mean_squared_error: 0.2461\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 1s 759us/step - loss: 0.0483 - mean_squared_error: 0.0483\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 1s 881us/step - loss: 0.0479 - mean_squared_error: 0.0479\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 1s 787us/step - loss: 0.0487 - mean_squared_error: 0.0487\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 1s 818us/step - loss: 0.0487 - mean_squared_error: 0.0487\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 1s 833us/step - loss: 0.0498 - mean_squared_error: 0.0498\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 1s 852us/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 1s 861us/step - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "y_pred_proba：推定値\n",
      " [12.423549 11.907965 11.791387 12.317888 11.863736 11.476696 12.241206\n",
      " 11.793154 13.534725 12.060556 12.184896 12.157908 12.428518 11.753883\n",
      " 11.725192 11.882213 12.36068  11.951797 11.895898 11.868228]\n",
      "y_test：正解値\n",
      " [[12.20918779]\n",
      " [11.79810441]\n",
      " [11.60823564]\n",
      " [12.16525065]\n",
      " [11.38509209]\n",
      " [11.35040654]\n",
      " [12.55292652]\n",
      " [11.85651517]\n",
      " [13.5211395 ]\n",
      " [11.9103584 ]\n",
      " [12.24961095]\n",
      " [11.82704253]\n",
      " [12.32385568]\n",
      " [11.71993963]\n",
      " [11.68855803]\n",
      " [11.88448902]\n",
      " [12.15477935]\n",
      " [11.72480582]\n",
      " [11.91404782]\n",
      " [11.9511804 ]]\n",
      "Train loss: 0.04809340375936261\n",
      "Train mse: 0.04809340375936261\n"
     ]
    }
   ],
   "source": [
    "#ラッパーとしてのkeras Sequentialモデルは以下のように書けます。ロジスティック回帰の例です。\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#データの読み込み\n",
    "Ames = pd.read_csv(\"../../dic_ml_ans/train.csv\")\n",
    "Ames.head(4)\n",
    "\n",
    "# GrLivAreaとYearBuiltと目的変数SalePriceを抜き出す\n",
    "Ames = Ames.loc[:, [\"GrLivArea\", \"YearBuilt\", \"SalePrice\"]]\n",
    "Ames.head()\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = Ames.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = Ames[\"SalePrice\"]\n",
    "y = np.array(y)[:, np.newaxis]\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_test{}\".format(X_test.shape))\n",
    "print(\"X_train{}\".format(X_train.shape))\n",
    "print(\"y_train{}\".format(y_train.shape))\n",
    "print(\"X_val{}\".format(X_train.shape))\n",
    "print(\"y_val{}\".format(y_val.shape))\n",
    "\n",
    "# 特徴量データを正規化する\n",
    "mean_train = X_train.mean(axis=0)\n",
    "std_train = X_train.std(axis=0)\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "mean_test = X_test.mean(axis=0)\n",
    "std_test = X_test.std(axis=0)\n",
    "X_test = (X_test - mean_test) / std_test\n",
    "mean_val = X_val.mean(axis=0)\n",
    "std_val = X_val.std(axis=0)\n",
    "X_val = (X_val - mean_val) / std_val\n",
    "\n",
    "y_test = np.log(y_test)\n",
    "y_train = np.log(y_train)\n",
    "y_val = np.log(y_val)\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(2,)) # 入力層\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(input_data) # 出力層\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,)))\n",
    "#model.add(Activation('sigmoid'))#不要？\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['mse'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "\n",
    "print(\"y_pred_proba：推定値\\n\", y_pred_proba[:20])\n",
    "print(\"y_test：正解値\\n\", y_test[:20])\n",
    "\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train mse:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。\n",
    "\n",
    "##### 【問題3】Iris（多値分類）をKerasで学習 →PyTorchに書き換え\n",
    "自力で書くのは時間がかかりそうだったので、下記のサイトを写経して、何をしているか読み解きをしてコメントをつけて学習しました m( )m\n",
    "\n",
    "http://aidiary.hatenablog.com/entry/20180225/1519520981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 8,180\n",
      "Trainable params: 8,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.4888 - acc: 0.8501\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 61us/sample - loss: 0.3308 - acc: 0.9044\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 61us/sample - loss: 0.3113 - acc: 0.9125\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 0.3001 - acc: 0.9171\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 61us/sample - loss: 0.2890 - acc: 0.9190\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s 57us/sample - loss: 0.2824 - acc: 0.9214\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.2746 - acc: 0.9234\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s 63us/sample - loss: 0.2755 - acc: 0.9244\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 0.2701 - acc: 0.9243\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 0.2671 - acc: 0.9250\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.2657 - acc: 0.9277\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 0.2670 - acc: 0.9270\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.2610 - acc: 0.9287\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 63us/sample - loss: 0.2573 - acc: 0.9309\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 60us/sample - loss: 0.2551 - acc: 0.9309\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 62us/sample - loss: 0.2596 - acc: 0.9298\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.2531 - acc: 0.9313\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 62us/sample - loss: 0.2542 - acc: 0.9311\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 63us/sample - loss: 0.2482 - acc: 0.9323\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 59us/sample - loss: 0.2518 - acc: 0.9311\n",
      "y_pred_proba\n",
      " [[3.7216039e-06 1.5240841e-04 1.8921246e-04 ... 9.9402630e-01\n",
      "  2.8221747e-03 4.8014248e-04]\n",
      " [1.2252580e-07 5.0028376e-02 9.4610083e-01 ... 3.3647061e-04\n",
      "  2.4941830e-05 2.7420416e-13]\n",
      " [1.4033970e-16 9.9996412e-01 1.7094392e-06 ... 3.4816530e-08\n",
      "  2.6083094e-06 6.5227346e-12]\n",
      " ...\n",
      " [6.9206359e-04 1.9105629e-03 2.1050891e-02 ... 7.2326581e-03\n",
      "  3.2905298e-03 6.2103551e-03]\n",
      " [4.6273445e-19 5.6018498e-13 2.7744668e-20 ... 1.8667477e-23\n",
      "  2.4283153e-09 1.6787668e-08]\n",
      " [9.2630117e-08 9.4129708e-09 2.7330464e-06 ... 7.1305585e-14\n",
      "  1.2368841e-07 6.1191654e-18]]\n",
      "y_pred(予測値)[7 2 1 0 4 1 9 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "y_test（正解） [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Train loss: 0.28780399629846215\n",
      "Train accuracy: 0.9243125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KerasのFunctional API 4層のニューラルネットワークで実装したニューラルネットワークを使いMNISTを多値分類する\n",
    "\"\"\"\n",
    "K.clear_session()\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# データセットを確認\n",
    "# print(X_train.shape) # (60000, 28, 28)\n",
    "# print(X_test.shape) # (10000, 28, 28)\n",
    "# print(X_train[0].dtype) # uint8\n",
    "#print(X_train[0])\n",
    "\n",
    "#平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "#２２５で割る\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255 # 全て２５５で割っている\n",
    "X_test /= 255\n",
    "\n",
    "#trainをさらに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "# print(X_train.shape) # (48000, 784)\n",
    "# print(X_val.shape) # (12000, 784)\n",
    "\n",
    "# yをone-hot表現に変換\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "# print(y_train.shape) # (60000,)\n",
    "# print(y_train_one_hot.shape) # (60000, 10)\n",
    "# print(y_test_one_hot.dtype) # float64\n",
    "# print(y_val_one_hot.dtype) # float64\n",
    "    \n",
    "# Functional API 4層のニューラルネットワーク\n",
    "input_data = tf.keras.layers.Input(shape=(784,))\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(X)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=20,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "#最大値のインデックスを取る\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "print(\"y_pred_proba\\n\", y_pred_proba)\n",
    "print(\"y_pred(予測値)\", y_pred[:20],sep=\"\")\n",
    "print(\"y_test（正解）\", y_test[:20])\n",
    "\n",
    "score = model.evaluate(X_train, y_train_one_hot, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[[6.3 2.5 5.  1.9]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[2 0 0 0 0 1 1 1 1 2]\n",
      "[-2.47274423e-15  3.85247390e-16 -4.26603197e-16 -7.66053887e-17]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み（下のやり方より簡単）\n",
    "iris = load_iris()\n",
    "X = iris.data #.dataでデータ本体を取得\n",
    "y = iris.target # .targetでクラスラベルが取得できる\n",
    "print(X.shape)  # (150, 4)\n",
    "print(y.shape)  # (150, )\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=5)\n",
    "\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])\n",
    "\n",
    "# データの標準化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(np.mean(X_train, axis=0))  # [ -2.47274423e-15   3.85247390e-16  -4.26603197e-16  -7.66053887e-17]\n",
    "print(np.std(X_train, axis=0))   # [ 1.  1.  1.  1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.2592 val_loss: 1.2664 val_acc: 0.2200\n",
      "epoch 1000, loss: 0.3125 val_loss: 0.3263 val_acc: 0.9200\n",
      "epoch 2000, loss: 0.2467 val_loss: 0.2647 val_acc: 0.9400\n",
      "epoch 3000, loss: 0.2087 val_loss: 0.2312 val_acc: 0.9400\n",
      "epoch 4000, loss: 0.1828 val_loss: 0.2086 val_acc: 0.9400\n",
      "epoch 5000, loss: 0.1639 val_loss: 0.1920 val_acc: 0.9400\n",
      "epoch 6000, loss: 0.1494 val_loss: 0.1792 val_acc: 0.9400\n",
      "epoch 7000, loss: 0.1380 val_loss: 0.1690 val_acc: 0.9400\n",
      "epoch 8000, loss: 0.1288 val_loss: 0.1608 val_acc: 0.9400\n",
      "epoch 9000, loss: 0.1211 val_loss: 0.1539 val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "input_size = 4\n",
    "num_classes = 3 \n",
    "num_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "#ロジスティック回帰クラス\n",
    "class LogisticRegression(nn.Module):# nn.Module:すべてのニューラルネットワークモジュールの基本クラス\n",
    "\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()#super関数\n",
    "        self.linear = nn.Linear(input_size, num_classes)#nn.Liner入力に重みとバイアスによる線形変換を行う関数\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# modelの定義\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# loss関数の定義\n",
    "criterion = nn.CrossEntropyLoss()#この中にsoftmaxが含まれている\n",
    "\n",
    "# 最適化手法のパラメータ設定\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# lossを求める \n",
    "def train(X_train, y_train):\n",
    "    inputs = torch.from_numpy(X_train).float()#numpyからTensorを生成。データタイプ指定\n",
    "    targets = torch.from_numpy(y_train).long()\n",
    "        \n",
    "    # 勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "    # 順伝播\n",
    "    outputs = model(inputs)\n",
    "    # ロスの計算\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()# 勾配の計算\n",
    "    \n",
    "    # パラメータ(重み・バイアス）の更新\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()#.item()はtapleの値のみを取り出すっぽい\n",
    "\n",
    "#検証\n",
    "def valid(X_test, y_test):\n",
    "    inputs = torch.from_numpy(X_test).float()\n",
    "    targets = torch.from_numpy(y_test).long()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    val_loss = criterion(outputs, targets)#誤差\n",
    "    \n",
    "    # 精度を求める\n",
    "    _, predicted = torch.max(outputs, 1)#最大値のインデックス\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    val_acc = float(correct) / targets.size(0)#正解数をサンプル数で割って正解率を出す\n",
    "\n",
    "    return val_loss.item(), val_acc\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    perm = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(perm)#trainデータをepocごとにシャッフルしている。この人独自の手法？\n",
    "    X_train = X_train[perm]\n",
    "    y_train = y_train[perm]\n",
    "    \n",
    "    loss = train(X_train, y_train)\n",
    "    val_loss, val_acc = valid(X_test, y_test)\n",
    "    \n",
    "    if epoch % 1000 == 0:#epoc1000回ごとにプリントする\n",
    "        print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n",
    "              % (epoch, loss, val_loss, val_acc))\n",
    "    \n",
    "    # logging\n",
    "    loss_list.append(loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a368feef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a36512ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a368eb5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve　学習曲線とアキュラシー\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), loss_list, 'r-', label='train_loss')\n",
    "plt.plot(range(num_epochs), val_loss_list, 'b-', label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), val_acc_list, 'g-', label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】（アドバンス課題）フレームワークの比較\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "\n",
    "《視点例》  \n",
    "計算速度  \n",
    "コードの行数・可読性  \n",
    "用意されている機能  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。  \n",
    "\n",
    "TensorFlow: ・計算速度　＝　BAD：TensorFlowだと、行列演算において最先端のディープラーニングツールの4倍の時間が掛かる BAD：計算グラフは単なるPythonなため、遅い。  \n",
    "\n",
    "・コードの行数・可読性　＝　BAD:計算グラフの定義と、実行・学習を行うセッションが別々でややわかりにくい BAD：書き方に個人差が出やすい ・用意されている機能　＝　GOOD：TensorBoardを使用して視覚化することができる。  \n",
    "\n",
    "GOOD：ニューラルネットに特化したライブラリが豊富 Pytorch ・計算速度　＝　GOOD：３つの中で最速 ・コードの行数・可読性　＝　GOOD:pythonを書くようにかける。  \n",
    "\n",
    "直感的で可読性も良い ・用意されている機能　＝　GOOD：簡単に組み合わせることのできるモジュールのピースが多くある。  \n",
    "\n",
    "GOOD:前もってトレーニングされたモデルが多くある。 BAD：日本語の文献がまだ少ない Keras ・計算速度　＝　BAD：TensorFlowよりわずかに速いくらい、Pytorchにかなり劣る ・コードの行数・可読性　＝　GOOD：直感的なAPI。  \n",
    "\n",
    "行数が少なく初心者でも書きやすく理解しやすい ・用意されている機能　＝　GOOD：フレームワークが急速な成長を続けている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
