{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 線形回帰\n",
    "\n",
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "スクラッチを通して線形回帰を理解する\n",
    "オブジェクト指向を意識した実装に慣れる\n",
    "数式をコードに落とし込めるようにする\n",
    "### どのように学ぶか\n",
    "スクラッチで線形回帰を実装した後、学習と検証を行なっていきます。\n",
    "\n",
    "## 2.線形回帰スクラッチ\n",
    "線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "`雛形`  \n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手作りデータ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  2,  3,  4],\n",
       "       [ 4, -5,  6,  7],\n",
       "       [ 7,  8, -9, 10]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-1, 2, 3, 4], [4, -5, 6, 7], [7, 8, -9, 10]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shita = [rd.random() for i in range(4)]\n",
    "# print(shita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tominagashuuji/workspace/dic_ml/sprint'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DLしたデータは個人的に別ディレクトリに保存したいのでosライブラリをインポート\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#仮データを作成（HousePrise）\n",
    "df = pd.read_csv(\"../../dic_ml_ans/house-prices-advanced-regression-techniques/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の分割\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスの分割\n",
    "y = df.loc[:, [\"SalePrice\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.25, #検証用データをどれくらいの比率にするか指定\n",
    "    random_state=42 #ランダム具合の調整\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラス生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter=10, lr=0.01, bias=True, verbose=True):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        self.h = None\n",
    "        self.j_theta = None\n",
    "        self.error = None\n",
    "        self.theta = np.zeros((100, 3))\n",
    "\n",
    "    def _linear_hypothesis(self, X): # 問1 \n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        #(サンプル数 x 特徴量数) @ (特徴量数 x 1) = (サンプル数 x 1)\n",
    "        self.h = np.dot(X, self.theta)\n",
    "        return self.h\n",
    "    \n",
    "    def _get_error(self, y):\n",
    "        \"\"\"\n",
    "        説明を記述\n",
    "        \"\"\"\n",
    "        self.error = self.h - y # self.errorは予測値と実績値の誤差を求める\n",
    "        return self.error\n",
    "\n",
    "    def _gradient_descent(self, X): # 問2 最急降下法\n",
    "        m = X.shape[0] # m はサンプル数の平均を出す時に使うので、Xのレコード数を取得\n",
    "#         self.theta = self.theta - (self.lr / m *(X.T@self.error).sum())\n",
    "        print(\"self.theta{}\".format(self.theta))\n",
    "        print(\"self.lr / m *(X.T@self.error).sum(){}\".format(self.lr / m *(X.T@self.error).sum()))\n",
    "#         self.theta = self.theta - self.lr / m *(X.T@self.error).sum()\n",
    "        self.theta = self.theta - self.lr/m*(self.error.T@X).sum()\n",
    "        print(\"self.theta.shape{}\".format(self.theta.shape))\n",
    "        print(\"self.theta{}\".format(self.theta))\n",
    "\n",
    "        return self.theta\n",
    "\n",
    "    def loss_function(self, error):\n",
    "        m = error.shape[0]\n",
    "        self.j_theta = (error**2).sum()/2/m\n",
    "#         print(\"m{}\".format(m))\n",
    "\n",
    "        return self.j_theta\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        # 検証用データの有無を判断する。\n",
    "        self.val_enable = False\n",
    "        if X_val is not None:\n",
    "            self.val_enable = True\n",
    "\n",
    "        # bias（切片）の有無を判定し、有なら切片に影響が出ないように0列目に1を追加する\n",
    "        if self.bias:\n",
    "            X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "            if self.val_enable:\n",
    "                X_val = np.concatenate([np.ones((X_val.shape[0], 1)), X_val], axis=1)\n",
    "\n",
    "        # 適当なthetaを用意する（これを更新して正解に近づけて行くイメージ）\n",
    "        self.theta = np.array([rd.random() for i in range(3)])\n",
    "\n",
    "        for i in range(self.iter):\n",
    "            # 訓練用データの処理\n",
    "            self._linear_hypothesis(X)# 引数のself は不要\n",
    "            self._get_error(y)\n",
    "            self._gradient_descent(X)\n",
    "            self.loss_function(self.error) # 最適化されたthetaで目的関数を算出\n",
    "            self.loss[i] = self.j_theta # 問5、目的関数算出\n",
    "\n",
    "            if self.val_enable:\n",
    "                # 検証用データの処理\n",
    "                self._linear_hypothesis(X_val)# 引数のself は不要\n",
    "                self._get_error(y_val)\n",
    "                self._gradient_descent(X_val)\n",
    "                self.loss_function(self.error) # 最適化されたthetaで目的関数を算出           \n",
    "                self.val_loss[i] = self.j_theta # 問5、目的関数算出\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(\"self.loss{}\".format(self.loss))\n",
    "            print(\"self.val_loss{}\".format(self.val_loss))\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            self.learning_curve()\n",
    "            print()\n",
    "        return\n",
    "\n",
    "    def predict(self, X):# 問3 推定\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "#      切片の確認、学習後に再度実行するので\n",
    "        n_samples = X.shape[0]\n",
    "        if self.bias:\n",
    "            X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "\n",
    "        #(サンプル数 x 特徴量数) @ (特徴量数 x 1) = (サンプル数 x 1)\n",
    "        y_pred = np.dot(X, self.theta)\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def learning_curve(self):\n",
    "        plt.title(\"model loss\")\n",
    "        plt.xlabel(\"iter\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(np.arange(self.iter), self.loss, label=\"train_loss\")\n",
    "        if self.val_enable:\n",
    "            plt.plot(np.arange(self.iter), self.val_loss, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = ScratchLinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  学習（線形回帰） 問１、問２動作確認、問５"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.theta[0.2699999  0.92837327 0.85534771]\n",
      "self.lr / m *(X.T@self.error).sum()-7176629075.158014\n",
      "self.theta.shape(3,)\n",
      "self.theta[7.17662908e+09 7.17662908e+09 7.17662908e+09]\n",
      "self.theta[7.17662908e+09 7.17662908e+09 7.17662908e+09]\n",
      "self.lr / m *(X.T@self.error).sum()3.101508849324024e+17\n",
      "self.theta.shape(3,)\n",
      "self.theta[-3.10150878e+17 -3.10150878e+17 -3.10150878e+17]\n",
      "self.theta[-3.10150878e+17 -3.10150878e+17 -3.10150878e+17]\n",
      "self.lr / m *(X.T@self.error).sum()-4.1681862143637615e+25\n",
      "self.theta.shape(3,)\n",
      "self.theta[4.16818618e+25 4.16818618e+25 4.16818618e+25]\n",
      "self.theta[4.16818618e+25 4.16818618e+25 4.16818618e+25]\n",
      "self.lr / m *(X.T@self.error).sum()1.8013563603402778e+33\n",
      "self.theta.shape(3,)\n",
      "self.theta[-1.80135632e+33 -1.80135632e+33 -1.80135632e+33]\n",
      "self.theta[-1.80135632e+33 -1.80135632e+33 -1.80135632e+33]\n",
      "self.lr / m *(X.T@self.error).sum()-2.42088258105834e+41\n",
      "self.theta.shape(3,)\n",
      "self.theta[2.42088256e+41 2.42088256e+41 2.42088256e+41]\n",
      "self.theta[2.42088256e+41 2.42088256e+41 2.42088256e+41]\n",
      "self.lr / m *(X.T@self.error).sum()1.0462277860808285e+49\n",
      "self.theta.shape(3,)\n",
      "self.theta[-1.04622776e+49 -1.04622776e+49 -1.04622776e+49]\n",
      "self.theta[-1.04622776e+49 -1.04622776e+49 -1.04622776e+49]\n",
      "self.lr / m *(X.T@self.error).sum()-1.4060486191992914e+57\n",
      "self.theta.shape(3,)\n",
      "self.theta[1.40604861e+57 1.40604861e+57 1.40604861e+57]\n",
      "self.theta[1.40604861e+57 1.40604861e+57 1.40604861e+57]\n",
      "self.lr / m *(X.T@self.error).sum()6.076491051225545e+64\n",
      "self.theta.shape(3,)\n",
      "self.theta[-6.07649091e+64 -6.07649091e+64 -6.07649091e+64]\n",
      "self.theta[-6.07649091e+64 -6.07649091e+64 -6.07649091e+64]\n",
      "self.lr / m *(X.T@self.error).sum()-8.166330473937976e+72\n",
      "self.theta.shape(3,)\n",
      "self.theta[8.16633041e+72 8.16633041e+72 8.16633041e+72]\n",
      "self.theta[8.16633041e+72 8.16633041e+72 8.16633041e+72]\n",
      "self.lr / m *(X.T@self.error).sum()3.529226043015027e+80\n",
      "self.theta.shape(3,)\n",
      "self.theta[-3.52922596e+80 -3.52922596e+80 -3.52922596e+80]\n",
      "self.theta[-3.52922596e+80 -3.52922596e+80 -3.52922596e+80]\n",
      "self.lr / m *(X.T@self.error).sum()-4.743004793642604e+88\n",
      "self.theta.shape(3,)\n",
      "self.theta[4.74300476e+88 4.74300476e+88 4.74300476e+88]\n",
      "self.theta[4.74300476e+88 4.74300476e+88 4.74300476e+88]\n",
      "self.lr / m *(X.T@self.error).sum()2.0497745092841717e+96\n",
      "self.theta.shape(3,)\n",
      "self.theta[-2.04977446e+96 -2.04977446e+96 -2.04977446e+96]\n",
      "self.theta[-2.04977446e+96 -2.04977446e+96 -2.04977446e+96]\n",
      "self.lr / m *(X.T@self.error).sum()-2.7547372157311968e+104\n",
      "self.theta.shape(3,)\n",
      "self.theta[2.7547372e+104 2.7547372e+104 2.7547372e+104]\n",
      "self.theta[2.7547372e+104 2.7547372e+104 2.7547372e+104]\n",
      "self.lr / m *(X.T@self.error).sum()1.190509048641654e+112\n",
      "self.theta.shape(3,)\n",
      "self.theta[-1.19050902e+112 -1.19050902e+112 -1.19050902e+112]\n",
      "self.theta[-1.19050902e+112 -1.19050902e+112 -1.19050902e+112]\n",
      "self.lr / m *(X.T@self.error).sum()-1.5999513932404183e+120\n",
      "self.theta.shape(3,)\n",
      "self.theta[1.59995138e+120 1.59995138e+120 1.59995138e+120]\n",
      "self.theta[1.59995138e+120 1.59995138e+120 1.59995138e+120]\n",
      "self.lr / m *(X.T@self.error).sum()6.914476633786479e+127\n",
      "self.theta.shape(3,)\n",
      "self.theta[-6.91447647e+127 -6.91447647e+127 -6.91447647e+127]\n",
      "self.theta[-6.91447647e+127 -6.91447647e+127 -6.91447647e+127]\n",
      "self.lr / m *(X.T@self.error).sum()-9.292517798480783e+135\n",
      "self.theta.shape(3,)\n",
      "self.theta[9.29251773e+135 9.29251773e+135 9.29251773e+135]\n",
      "self.theta[9.29251773e+135 9.29251773e+135 9.29251773e+135]\n",
      "self.lr / m *(X.T@self.error).sum()4.0159280749465465e+143\n",
      "self.theta.shape(3,)\n",
      "self.theta[-4.01592798e+143 -4.01592798e+143 -4.01592798e+143]\n",
      "self.theta[-4.01592798e+143 -4.01592798e+143 -4.01592798e+143]\n",
      "self.lr / m *(X.T@self.error).sum()-5.397094399236325e+151\n",
      "self.theta.shape(3,)\n",
      "self.theta[5.39709436e+151 5.39709436e+151 5.39709436e+151]\n",
      "self.theta[5.39709436e+151 5.39709436e+151 5.39709436e+151]\n",
      "self.lr / m *(X.T@self.error).sum()2.3324510526709375e+159\n",
      "self.theta.shape(3,)\n",
      "self.theta[-2.332451e+159 -2.332451e+159 -2.332451e+159]\n",
      "self.loss[2.07892624e+013 6.61341691e+044 2.23089498e+076 7.52544788e+107\n",
      " 2.53854916e+139 8.56325355e+170 2.88863074e+202 9.74417901e+233\n",
      " 3.28699073e+265 1.10879614e+297]\n",
      "self.val_loss[1.13901859e+029 3.84223600e+060 1.29609628e+092 4.37210404e+123\n",
      " 1.47483594e+155 4.97504414e+186 1.67822491e+218 5.66113341e+249\n",
      " 1.90966248e+281             inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:81: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0ca12b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "slr.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推定 問3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred[-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 -8.42481301e+162\n",
      " -8.46213222e+162 -6.07136995e+162 -9.08256419e+162 -8.01196918e+162\n",
      " -6.06670505e+162 -7.81137839e+162 -7.94432810e+162 -6.63115819e+162\n",
      " -6.60083633e+162 -8.25687654e+162 -8.60907664e+162 -6.90871986e+162\n",
      " -8.68837997e+162 -7.21893584e+162 -6.84107878e+162 -8.12392683e+162\n",
      " -8.77234821e+162 -8.39449114e+162 -8.12159438e+162 -6.74778074e+162\n",
      " -8.00263938e+162 -7.44751604e+162 -7.80904594e+162 -6.56818201e+162\n",
      " -8.40148850e+162 -7.83470290e+162 -7.37287761e+162 -9.44642654e+162\n",
      " -1.17392259e+163 -6.78509996e+162 -8.49711899e+162 -7.23526300e+162\n",
      " -8.99159860e+162 -9.17119733e+162 -1.05286838e+163 -6.62182839e+162\n",
      " -7.25625506e+162 -9.57471135e+162 -6.81542182e+162 -9.44875900e+162\n",
      " -6.88073045e+162 -9.54205704e+162 -6.71046152e+162 -6.81542182e+162\n",
      " -1.00412015e+163 -8.12392683e+162 -6.85507349e+162 -8.26853879e+162\n",
      " -7.65277173e+162 -1.13706986e+163 -6.65448270e+162 -8.72336674e+162\n",
      " -8.79100781e+162 -7.23992790e+162 -7.21660339e+162 -6.49121113e+162\n",
      " -5.70984004e+162 -7.47783790e+162 -1.04447156e+163 -8.19856526e+162\n",
      " -8.82366213e+162 -9.58404115e+162 -6.93904172e+162 -9.95023596e+162\n",
      " -6.91804966e+162 -8.06561555e+162 -8.19856526e+162 -7.41719418e+162\n",
      " -6.68247211e+162 -6.97636094e+162 -1.02021407e+163 -7.66909888e+162\n",
      " -1.02394599e+163 -1.02907738e+163 -7.25392261e+162 -6.42123760e+162\n",
      " -6.90405496e+162 -6.99268809e+162 -6.86440329e+162 -6.58917407e+162\n",
      " -7.88135192e+162 -8.18457055e+162 -9.20385164e+162 -8.02363144e+162\n",
      " -6.65448270e+162 -8.07727781e+162 -8.18223810e+162 -8.37349909e+162\n",
      " -6.52853035e+162 -1.10021714e+163 -8.71636938e+162 -7.74840222e+162\n",
      " -8.10293477e+162 -8.05162085e+162 -8.17524075e+162 -1.01088426e+163\n",
      " -8.46213222e+162 -8.79800517e+162 -9.78929684e+162 -6.49354358e+162\n",
      " -7.95599036e+162 -8.01430163e+162 -6.98802319e+162 -8.69537732e+162\n",
      " -6.96236623e+162 -9.44642654e+162 -6.38391838e+162 -7.04166957e+162\n",
      " -7.00435035e+162 -8.00963673e+162 -8.87264360e+162 -6.40257799e+162\n",
      " -6.66148005e+162 -6.63349064e+162 -9.05224233e+162 -8.47379448e+162\n",
      " -6.45155946e+162 -6.65448270e+162 -8.39215869e+162 -8.79800517e+162\n",
      " -7.93266585e+162 -6.76644035e+162 -9.92924390e+162 -6.68480456e+162\n",
      " -7.21893584e+162 -8.49245409e+162 -8.36650173e+162 -9.40910733e+162\n",
      " -8.81199987e+162 -9.66101204e+162 -5.66785593e+162 -8.68837997e+162\n",
      " -8.65572566e+162 -6.79676221e+162 -8.52977330e+162 -1.47200983e+163\n",
      " -1.11724403e+163 -6.72912113e+162 -8.67205281e+162 -8.44347262e+162\n",
      " -7.02534241e+162 -6.68946946e+162 -9.31580929e+162 -8.00497183e+162\n",
      " -6.39324819e+162 -6.48188133e+162 -7.23759545e+162 -7.73207506e+162\n",
      " -1.04330533e+163 -9.87792998e+162 -6.99735300e+162 -8.78634291e+162\n",
      " -7.52915182e+162 -7.76706183e+162 -5.89177122e+162 -7.24459280e+162\n",
      " -7.56180614e+162 -7.08365368e+162 -8.52277595e+162 -8.12625928e+162\n",
      " -7.37987496e+162 -8.77468066e+162 -9.20851654e+162 -1.06872905e+163\n",
      " -1.13683662e+163 -1.01321671e+163 -9.20851654e+162 -6.62182839e+162\n",
      " -8.04462349e+162 -8.24987918e+162 -1.13473741e+163 -8.27553614e+162\n",
      " -8.00730428e+162 -8.64872830e+162 -7.69475584e+162 -8.33617987e+162\n",
      " -7.53614918e+162 -6.99035564e+162 -6.83641388e+162 -7.78105653e+162\n",
      " -9.31114439e+162 -8.47146203e+162 -8.61140909e+162 -8.17990565e+162\n",
      " -7.86968967e+162 -7.14429741e+162 -7.78338898e+162 -6.98569074e+162\n",
      " -7.57813329e+162 -7.22126829e+162 -7.72507771e+162 -9.22950860e+162\n",
      " -7.58746310e+162 -7.55247633e+162 -8.72103428e+162 -7.61545251e+162\n",
      " -8.18457055e+162 -8.03062879e+162 -7.61545251e+162 -1.07969157e+163\n",
      " -7.79271879e+162 -6.87606554e+162 -9.36712321e+162 -7.19561133e+162\n",
      " -8.24754673e+162 -6.66847741e+162 -9.87559753e+162 -7.61078761e+162\n",
      " -7.42885643e+162 -8.09593742e+162 -7.73907241e+162 -8.33851232e+162\n",
      " -7.95132545e+162 -7.23992790e+162 -7.72274526e+162 -8.65805811e+162\n",
      " -6.69180192e+162 -7.76939428e+162 -8.45513487e+162 -7.16762192e+162\n",
      " -8.10293477e+162 -7.40319947e+162 -7.11164310e+162 -6.75477809e+162\n",
      " -8.39449114e+162 -7.18161662e+162 -6.71046152e+162 -8.15191624e+162\n",
      " -6.58684162e+162 -7.43118888e+162 -9.11521850e+162 -7.72507771e+162\n",
      " -7.50116241e+162 -6.97169604e+162 -9.44875900e+162 -6.77343770e+162\n",
      " -6.17866270e+162 -1.15363026e+163 -8.71870183e+162 -1.15502973e+163\n",
      " -8.98226880e+162 -7.59912535e+162 -7.91633869e+162 -7.28890937e+162\n",
      " -7.08365368e+162 -6.38625083e+162 -8.96594164e+162 -8.07961026e+162\n",
      " -8.03762614e+162 -6.09236201e+162 -7.29590672e+162 -7.10697819e+162\n",
      " -7.34955310e+162 -7.63877702e+162 -8.38749379e+162 -9.53039478e+162\n",
      " -9.28315497e+162 -7.43118888e+162 -6.69646682e+162 -8.47612693e+162\n",
      " -8.70937203e+162 -9.19218939e+162 -7.78105653e+162 -6.65215025e+162\n",
      " -6.90638741e+162 -8.00263938e+162 -9.52339743e+162 -7.76939428e+162\n",
      " -9.27615762e+162 -7.20494113e+162 -7.43352133e+162 -6.93437682e+162\n",
      " -8.66272301e+162 -9.04291252e+162 -8.02829634e+162 -8.17290830e+162\n",
      " -8.81433232e+162 -6.06670505e+162 -8.35717193e+162 -6.33726936e+162\n",
      " -8.69071242e+162 -8.06561555e+162 -8.96127674e+162 -7.15829212e+162\n",
      " -8.24754673e+162 -8.07494536e+162 -8.04928840e+162 -6.61249858e+162\n",
      " -7.63177967e+162 -8.31518781e+162 -6.31394485e+162 -8.64406340e+162\n",
      " -8.43414281e+162 -6.68713701e+162 -8.31752026e+162 -7.17695172e+162\n",
      " -7.93966320e+162 -8.17290830e+162 -6.71745888e+162 -7.12097290e+162\n",
      " -8.35017458e+162 -9.21784635e+162 -7.30990143e+162 -9.95956576e+162\n",
      " -9.82661606e+162 -6.48654623e+162 -7.93966320e+162 -8.48545673e+162\n",
      " -6.33493691e+162 -1.07386044e+163 -8.17524075e+162 -8.14025399e+162\n",
      " -7.47317300e+162 -7.59679290e+162 -9.00792576e+162 -6.97402849e+162\n",
      " -8.19156791e+162 -7.45218094e+162 -7.50582731e+162 -6.50753829e+162\n",
      " -8.55309781e+162 -8.38982624e+162 -6.62649329e+162 -7.71574790e+162\n",
      " -8.06794800e+162 -6.61249858e+162 -7.47317300e+162 -7.78572143e+162\n",
      " -6.52853035e+162 -7.79505124e+162 -7.93033340e+162 -7.05799672e+162\n",
      " -7.37287761e+162 -7.86735722e+162 -7.04633447e+162 -8.01430163e+162\n",
      " -8.52277595e+162 -6.56584956e+162 -8.96827409e+162 -8.16357850e+162\n",
      " -9.02658536e+162 -9.36712321e+162 -8.85398399e+162 -6.74544829e+162\n",
      " -1.07829210e+163 -6.82475162e+162 -1.08902137e+163 -1.08458971e+163\n",
      " -8.51577860e+162 -7.65976908e+162 -8.63706605e+162 -6.80842447e+162\n",
      " -6.90871986e+162 -6.75477809e+162 -8.57175742e+162 -9.58404115e+162\n",
      " -9.34613115e+162 -7.45917829e+162 -9.73098557e+162 -8.96827409e+162\n",
      " -7.24925770e+162]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = reg.predict(X_test)# 検証用データを推定させる\n",
    "y_pred = slr.predict(X_test)\n",
    "\n",
    "print(\"y_pred{}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価（問4、平均２乗誤差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "\n",
    "#     print(\"y_pred{}\".format(y_pred.shape))\n",
    "#     print(y_pred.reshape(365, 1).shape)\n",
    "#     print(\"y{}\".format(y.shape))\n",
    "    m = y.shape[0]\n",
    "    mse = ((y_pred - y)**2).sum()/m\n",
    "#     print(((y_pred.reshape(365, 1) - y)**2).shape)\n",
    "#     print(mse.shape)\n",
    "#     mse2 = np.average((y_pred.reshape(365, 1) - y)**2)\n",
    "#     print(mse2.shape)\n",
    "    print(\"m{}\".format(m))\n",
    "#     print(\"y_pred{}\".format(y_pred))\n",
    "#     print(\"y{}\".format(y))\n",
    "    print(\"(y_pred - y)){}\".format((y_pred - y)))\n",
    "    print(\"(y_pred - y)**2{}\".format((y_pred - y)**2))\n",
    "    print(\" ((y_pred - y)**2).sum(){}\".format(((y_pred - y)**2).sum()))\n",
    "    \n",
    "    print(\"mse{}\".format(mse))\n",
    "#     print(\"mse2{}\".format(mse2))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m365\n",
      "(y_pred - y))[[-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " ...\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]]\n",
      "(y_pred - y)**2[[inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " ...\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]]\n",
      " ((y_pred - y)**2).sum()inf\n",
      "mseinf\n",
      "<class 'numpy.float64'>\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in square\n",
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in square\n",
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in square\n"
     ]
    }
   ],
   "source": [
    "mse = MSE(y_pred, y_test)\n",
    "print(type(mse))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m365\n",
      "(y_pred - y))[[-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " ...\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]\n",
      " [-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 ... -9.73098557e+162\n",
      "  -8.96827409e+162 -7.24925770e+162]]\n",
      "(y_pred - y)**2[[inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " ...\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]\n",
      " [inf inf inf ... inf inf inf]]\n",
      " ((y_pred - y)**2).sum()inf\n",
      "mseinf\n",
      "MSE : inf\n",
      "[-7.07199143e+162 -1.07689263e+163 -6.89472515e+162 -8.42481301e+162\n",
      " -8.46213222e+162 -6.07136995e+162 -9.08256419e+162 -8.01196918e+162\n",
      " -6.06670505e+162 -7.81137839e+162 -7.94432810e+162 -6.63115819e+162\n",
      " -6.60083633e+162 -8.25687654e+162 -8.60907664e+162 -6.90871986e+162\n",
      " -8.68837997e+162 -7.21893584e+162 -6.84107878e+162 -8.12392683e+162\n",
      " -8.77234821e+162 -8.39449114e+162 -8.12159438e+162 -6.74778074e+162\n",
      " -8.00263938e+162 -7.44751604e+162 -7.80904594e+162 -6.56818201e+162\n",
      " -8.40148850e+162 -7.83470290e+162 -7.37287761e+162 -9.44642654e+162\n",
      " -1.17392259e+163 -6.78509996e+162 -8.49711899e+162 -7.23526300e+162\n",
      " -8.99159860e+162 -9.17119733e+162 -1.05286838e+163 -6.62182839e+162\n",
      " -7.25625506e+162 -9.57471135e+162 -6.81542182e+162 -9.44875900e+162\n",
      " -6.88073045e+162 -9.54205704e+162 -6.71046152e+162 -6.81542182e+162\n",
      " -1.00412015e+163 -8.12392683e+162 -6.85507349e+162 -8.26853879e+162\n",
      " -7.65277173e+162 -1.13706986e+163 -6.65448270e+162 -8.72336674e+162\n",
      " -8.79100781e+162 -7.23992790e+162 -7.21660339e+162 -6.49121113e+162\n",
      " -5.70984004e+162 -7.47783790e+162 -1.04447156e+163 -8.19856526e+162\n",
      " -8.82366213e+162 -9.58404115e+162 -6.93904172e+162 -9.95023596e+162\n",
      " -6.91804966e+162 -8.06561555e+162 -8.19856526e+162 -7.41719418e+162\n",
      " -6.68247211e+162 -6.97636094e+162 -1.02021407e+163 -7.66909888e+162\n",
      " -1.02394599e+163 -1.02907738e+163 -7.25392261e+162 -6.42123760e+162\n",
      " -6.90405496e+162 -6.99268809e+162 -6.86440329e+162 -6.58917407e+162\n",
      " -7.88135192e+162 -8.18457055e+162 -9.20385164e+162 -8.02363144e+162\n",
      " -6.65448270e+162 -8.07727781e+162 -8.18223810e+162 -8.37349909e+162\n",
      " -6.52853035e+162 -1.10021714e+163 -8.71636938e+162 -7.74840222e+162\n",
      " -8.10293477e+162 -8.05162085e+162 -8.17524075e+162 -1.01088426e+163\n",
      " -8.46213222e+162 -8.79800517e+162 -9.78929684e+162 -6.49354358e+162\n",
      " -7.95599036e+162 -8.01430163e+162 -6.98802319e+162 -8.69537732e+162\n",
      " -6.96236623e+162 -9.44642654e+162 -6.38391838e+162 -7.04166957e+162\n",
      " -7.00435035e+162 -8.00963673e+162 -8.87264360e+162 -6.40257799e+162\n",
      " -6.66148005e+162 -6.63349064e+162 -9.05224233e+162 -8.47379448e+162\n",
      " -6.45155946e+162 -6.65448270e+162 -8.39215869e+162 -8.79800517e+162\n",
      " -7.93266585e+162 -6.76644035e+162 -9.92924390e+162 -6.68480456e+162\n",
      " -7.21893584e+162 -8.49245409e+162 -8.36650173e+162 -9.40910733e+162\n",
      " -8.81199987e+162 -9.66101204e+162 -5.66785593e+162 -8.68837997e+162\n",
      " -8.65572566e+162 -6.79676221e+162 -8.52977330e+162 -1.47200983e+163\n",
      " -1.11724403e+163 -6.72912113e+162 -8.67205281e+162 -8.44347262e+162\n",
      " -7.02534241e+162 -6.68946946e+162 -9.31580929e+162 -8.00497183e+162\n",
      " -6.39324819e+162 -6.48188133e+162 -7.23759545e+162 -7.73207506e+162\n",
      " -1.04330533e+163 -9.87792998e+162 -6.99735300e+162 -8.78634291e+162\n",
      " -7.52915182e+162 -7.76706183e+162 -5.89177122e+162 -7.24459280e+162\n",
      " -7.56180614e+162 -7.08365368e+162 -8.52277595e+162 -8.12625928e+162\n",
      " -7.37987496e+162 -8.77468066e+162 -9.20851654e+162 -1.06872905e+163\n",
      " -1.13683662e+163 -1.01321671e+163 -9.20851654e+162 -6.62182839e+162\n",
      " -8.04462349e+162 -8.24987918e+162 -1.13473741e+163 -8.27553614e+162\n",
      " -8.00730428e+162 -8.64872830e+162 -7.69475584e+162 -8.33617987e+162\n",
      " -7.53614918e+162 -6.99035564e+162 -6.83641388e+162 -7.78105653e+162\n",
      " -9.31114439e+162 -8.47146203e+162 -8.61140909e+162 -8.17990565e+162\n",
      " -7.86968967e+162 -7.14429741e+162 -7.78338898e+162 -6.98569074e+162\n",
      " -7.57813329e+162 -7.22126829e+162 -7.72507771e+162 -9.22950860e+162\n",
      " -7.58746310e+162 -7.55247633e+162 -8.72103428e+162 -7.61545251e+162\n",
      " -8.18457055e+162 -8.03062879e+162 -7.61545251e+162 -1.07969157e+163\n",
      " -7.79271879e+162 -6.87606554e+162 -9.36712321e+162 -7.19561133e+162\n",
      " -8.24754673e+162 -6.66847741e+162 -9.87559753e+162 -7.61078761e+162\n",
      " -7.42885643e+162 -8.09593742e+162 -7.73907241e+162 -8.33851232e+162\n",
      " -7.95132545e+162 -7.23992790e+162 -7.72274526e+162 -8.65805811e+162\n",
      " -6.69180192e+162 -7.76939428e+162 -8.45513487e+162 -7.16762192e+162\n",
      " -8.10293477e+162 -7.40319947e+162 -7.11164310e+162 -6.75477809e+162\n",
      " -8.39449114e+162 -7.18161662e+162 -6.71046152e+162 -8.15191624e+162\n",
      " -6.58684162e+162 -7.43118888e+162 -9.11521850e+162 -7.72507771e+162\n",
      " -7.50116241e+162 -6.97169604e+162 -9.44875900e+162 -6.77343770e+162\n",
      " -6.17866270e+162 -1.15363026e+163 -8.71870183e+162 -1.15502973e+163\n",
      " -8.98226880e+162 -7.59912535e+162 -7.91633869e+162 -7.28890937e+162\n",
      " -7.08365368e+162 -6.38625083e+162 -8.96594164e+162 -8.07961026e+162\n",
      " -8.03762614e+162 -6.09236201e+162 -7.29590672e+162 -7.10697819e+162\n",
      " -7.34955310e+162 -7.63877702e+162 -8.38749379e+162 -9.53039478e+162\n",
      " -9.28315497e+162 -7.43118888e+162 -6.69646682e+162 -8.47612693e+162\n",
      " -8.70937203e+162 -9.19218939e+162 -7.78105653e+162 -6.65215025e+162\n",
      " -6.90638741e+162 -8.00263938e+162 -9.52339743e+162 -7.76939428e+162\n",
      " -9.27615762e+162 -7.20494113e+162 -7.43352133e+162 -6.93437682e+162\n",
      " -8.66272301e+162 -9.04291252e+162 -8.02829634e+162 -8.17290830e+162\n",
      " -8.81433232e+162 -6.06670505e+162 -8.35717193e+162 -6.33726936e+162\n",
      " -8.69071242e+162 -8.06561555e+162 -8.96127674e+162 -7.15829212e+162\n",
      " -8.24754673e+162 -8.07494536e+162 -8.04928840e+162 -6.61249858e+162\n",
      " -7.63177967e+162 -8.31518781e+162 -6.31394485e+162 -8.64406340e+162\n",
      " -8.43414281e+162 -6.68713701e+162 -8.31752026e+162 -7.17695172e+162\n",
      " -7.93966320e+162 -8.17290830e+162 -6.71745888e+162 -7.12097290e+162\n",
      " -8.35017458e+162 -9.21784635e+162 -7.30990143e+162 -9.95956576e+162\n",
      " -9.82661606e+162 -6.48654623e+162 -7.93966320e+162 -8.48545673e+162\n",
      " -6.33493691e+162 -1.07386044e+163 -8.17524075e+162 -8.14025399e+162\n",
      " -7.47317300e+162 -7.59679290e+162 -9.00792576e+162 -6.97402849e+162\n",
      " -8.19156791e+162 -7.45218094e+162 -7.50582731e+162 -6.50753829e+162\n",
      " -8.55309781e+162 -8.38982624e+162 -6.62649329e+162 -7.71574790e+162\n",
      " -8.06794800e+162 -6.61249858e+162 -7.47317300e+162 -7.78572143e+162\n",
      " -6.52853035e+162 -7.79505124e+162 -7.93033340e+162 -7.05799672e+162\n",
      " -7.37287761e+162 -7.86735722e+162 -7.04633447e+162 -8.01430163e+162\n",
      " -8.52277595e+162 -6.56584956e+162 -8.96827409e+162 -8.16357850e+162\n",
      " -9.02658536e+162 -9.36712321e+162 -8.85398399e+162 -6.74544829e+162\n",
      " -1.07829210e+163 -6.82475162e+162 -1.08902137e+163 -1.08458971e+163\n",
      " -8.51577860e+162 -7.65976908e+162 -8.63706605e+162 -6.80842447e+162\n",
      " -6.90871986e+162 -6.75477809e+162 -8.57175742e+162 -9.58404115e+162\n",
      " -9.34613115e+162 -7.45917829e+162 -9.73098557e+162 -8.96827409e+162\n",
      " -7.24925770e+162]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in square\n",
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in square\n",
      "/Users/tominagashuuji/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in square\n"
     ]
    }
   ],
   "source": [
    "# 評価のための指標値は回帰問題では 平均二乗誤差（Mean Squared Error, MSE） を使う。\n",
    "#MSEは値が小さいほど精度が高いです。\n",
    "print(\"MSE : {}\".format(MSE(y_pred, y_test)))\n",
    "\n",
    "# 推定値を表示\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的関数（損失関数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr.loss_function()\n",
    "# loss_functionはfitの中で動かす。\n",
    "# loss_functionは引数としてerrorを投入する必要があるが、\n",
    "# errorはfitで生成されるのでslr.loss_function(error)が使えない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5d2ffa4ee8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SalePrice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m plt.plot(loss_list, color='green', marker='o', linestyle='dashed',\n\u001b[0m\u001b[1;32m      5\u001b[0m          linewidth=1, markersize=2) # 「リスト名」のところに問５のリストの変数名を入れる\n\u001b[1;32m      6\u001b[0m plt.plot(val_loss, color='red', marker='x', linestyle='dashed',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_list' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c182171d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"linear_hypothesis_list\")\n",
    "plt.xlabel(\"theta\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.plot(loss_list, color='green', marker='o', linestyle='dashed',\n",
    "         linewidth=1, markersize=2) # 「リスト名」のところに問５のリストの変数名を入れる\n",
    "plt.plot(val_loss, color='red', marker='x', linestyle='dashed',\n",
    "         linewidth=1, markersize=2) # 「リスト名」のところに問５のリストの変数名を入れる\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------以下から動作確認のセル------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの読み込み\n",
    "# df = pd.read_csv(\"../../dic_ml_ans/house-prices-advanced-regression-techniques/train.csv\")\n",
    "# X = df.loc[:,['GrLivArea','YearBuilt']].values\n",
    "# y = df.SalePrice.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの前処理\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "# # 標準化\n",
    "# X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "# X_test_std = (X_test -X_test.mean()) / X_test.std()\n",
    "# y_train_std = (y_train - y_train.mean()) / y_train.std()\n",
    "# y_test_std = (y_test - y_test.mean()) / y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # バイアス項の追加\n",
    "# X_1 = np.insert(X_test_std, 0, 1, axis=1)\n",
    "# # シータの初期値\n",
    "# coef = np.random.rand(X_1.shape[1])\n",
    "# # パラメータ\n",
    "# lr = 0.001\n",
    "\n",
    "# # shapeの確認\n",
    "# print('X_1_shape :',X_1.shape)\n",
    "# print('coef_shape： 　',coef.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _linear_hypothesis(X,coef):\n",
    "#     \"\"\"\n",
    "#     線形の仮定関数を計算する\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#       学習データ\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#       次の形のndarray, shape (n_samples, 1)\n",
    "#       線形の仮定関数による推定結果\n",
    "\n",
    "#     \"\"\"\n",
    "#     hypothesis = np.dot(X,coef)\n",
    "#     return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis = _linear_hypothesis(X_1, coef)\n",
    "# print('hypothesis_shape: ' , hypothesis.shape, '\\n')\n",
    "# print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20191213\n",
    "def _linear_hypothesis(theta, X): # 問1 \n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    #(サンプル数 x 特徴量数) @ (特徴量数 x 1) = (サンプル数 x 1)\n",
    "#         print(X.shape)\n",
    "#         print(self.theta.shape)\n",
    "    h = np.dot(X, theta)\n",
    "#         print(self.h.shape)\n",
    "#         print(\"self.h.shape{}\".format(self.h.shape))\n",
    "#         print(\"self.h{}\".format(self.h))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1_shape : (365, 3)\n",
      "theta_shape： 　 (3,)\n"
     ]
    }
   ],
   "source": [
    "#仮データを作成（HousePrise）\n",
    "# バイアス項の追加\n",
    "X_1 = np.insert(X_test, 0, 1, axis=1)\n",
    "# シータの初期値\n",
    "theta = np.random.rand(X_1.shape[1])\n",
    "# パラメータ\n",
    "lr = 0.001\n",
    "\n",
    "# shapeの確認\n",
    "print('X_1_shape :',X_1.shape)\n",
    "print('theta_shape： 　',theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(365,)\n",
      "h[1513.87715972 1544.37126729 1486.03809044 1504.13843016 1550.06192361\n",
      " 1518.91421622 1499.23473126 1527.07044741 1517.37713851 1509.1236726 ]\n"
     ]
    }
   ],
   "source": [
    "# shapeと中身確認\n",
    "h = _linear_hypothesis(theta, X_1)\n",
    "print(\"h{}\".format(h.shape))\n",
    "print(\"h{}\".format(h[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "`雛形`  \n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。  \n",
    "雛形として用意されたメソッドや関数以外でも必要があれば各自作成して完成させてください。雛形を外れても問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20191212\n",
    "def _gradient_descent(theta, X): # 問2 最急降下法\n",
    "    m = X.shape[0] # m はサンプル数の平均を出す時に使うので、Xのレコード数を取得\n",
    "#     self.theta = self.theta - self.lr/m*(self.error.T@X).sum()\n",
    "    theta = theta - lr/m*(np.dot(error.T, X))\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1_shape(365, 3)\n",
      "h_shape(365,)\n",
      "theta_shape(3,)\n",
      "h_shape(365,)\n",
      "y_test_shape(365, 1)\n",
      "y_test_shape(365, 1)\n",
      "y_test_r_shape(365,)\n",
      "X_test_shape(365, 2)\n"
     ]
    }
   ],
   "source": [
    "# print(\"X_1{}\".format(X[:10]))\n",
    "print(\"X_1_shape{}\".format(X_1.shape))\n",
    "# print(\"h{}\".format(h[:10]))\n",
    "print(\"h_shape{}\".format(h.shape))\n",
    "print(\"theta_shape{}\".format(theta.shape))\n",
    "print(\"h_shape{}\".format(h.shape))\n",
    "\n",
    "print(\"y_test_shape{}\".format(y_test.shape))\n",
    "y_test.reshape(-1,1)\n",
    "print(\"y_test_shape{}\".format(y_test.shape))\n",
    "y_test = np.ravel(y_test)\n",
    "print(\"y_test_r_shape{}\".format(y_test.shape))\n",
    "\n",
    "print(\"X_test_shape{}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_shape(365,)\n"
     ]
    }
   ],
   "source": [
    "error = _linear_hypothesis(theta , X_1) - y_test\n",
    "print(\"error_shape{}\".format(error.shape))\n",
    "# print(\"error{}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "`仮定関数 `\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    ")\n",
    " の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "    print(X.shape)\n",
    "    print(theta.shape)\n",
    "    #(サンプル数 x 特徴量数) @ (特徴量数 x 1) = (サンプル数 x 1)\n",
    "    y_pred = np.dot(X, theta)\n",
    "\n",
    "    pass\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 3)\n",
      "(3,)\n",
      "[1513.87715972 1544.37126729 1486.03809044 1504.13843016 1550.06192361\n",
      " 1518.91421622 1499.23473126 1527.07044741 1517.37713851 1509.1236726\n",
      " 1488.73363188 1516.88725153 1491.61130471 1547.39150701 1544.98257521\n",
      " 1505.93426528 1548.18548358 1511.85479967 1480.58965023 1546.38262931\n",
      " 1512.42037405 1550.70170951 1547.90683172 1507.93087474 1543.10246917\n",
      " 1537.49554652 1548.86022935 1503.77917339 1542.30786685 1548.14319168\n",
      " 1472.39720766 1548.81606019 1509.47278146 1507.99954299 1549.362053\n",
      " 1515.70607746 1507.47407037 1548.30963189 1543.16496839 1507.69911942\n",
      " 1492.05304365 1542.1738835  1519.51904224 1552.64158739 1511.9967408\n",
      " 1454.98963089 1513.9761832  1515.6978068  1553.73169576 1511.9915104\n",
      " 1503.54281342 1526.77829449 1524.88102139 1531.72209516 1544.4430643\n",
      " 1549.01410714 1539.96760329 1524.88562603 1524.07846129 1506.69453348\n",
      " 1483.8578737  1511.56693852 1551.41718279 1550.34120123 1549.96290014\n",
      " 1508.56417874 1496.0548461  1549.74308148 1534.99282164 1543.21834683\n",
      " 1528.17803571 1518.33357641 1508.57495241 1503.76598522 1554.79207465\n",
      " 1540.19600548 1545.68977785 1542.72720833 1511.15492906 1519.557981\n",
      " 1520.4463764  1480.86861497 1506.61696883 1493.88258715 1526.83010855\n",
      " 1494.5254133  1550.66245787 1533.20588293 1544.4430643  1548.58953526\n",
      " 1504.45633366 1520.85744724 1527.39787307 1538.68646712 1520.72408964\n",
      " 1547.22014928 1486.73273065 1543.19259624 1548.7697894  1532.45723852\n",
      " 1521.7847814  1547.62294946 1526.51953708 1486.82840099 1526.96744504\n",
      " 1511.02555035 1518.30813869 1533.67766423 1537.36710644 1522.83165924\n",
      " 1491.97641763 1525.28507307 1512.98845144 1482.73982461 1550.05302721\n",
      " 1495.0677401  1506.24358526 1519.18428455 1528.9845747  1547.02639409\n",
      " 1539.48419821 1544.4430643  1542.29069979 1486.48318251 1534.56699826\n",
      " 1514.84343265 1547.41171433 1487.94457283 1538.60344771 1526.42605687\n",
      " 1547.59321998 1550.27588612 1543.82746462 1479.66441769 1500.59405784\n",
      " 1549.71397775 1551.18238721 1522.54169646 1546.36514937 1551.64151759\n",
      " 1545.87798976 1507.89654062 1533.63474657 1487.35932837 1507.67734772\n",
      " 1516.23029857 1497.37116652 1544.63525511 1519.50647982 1475.34323586\n",
      " 1482.84774449 1517.38447054 1515.47611089 1516.74741203 1482.40569267\n",
      " 1525.43832511 1519.30382822 1508.27788197 1478.84290178 1512.66625617\n",
      " 1548.40530224 1526.89081902 1550.17350951 1511.23155508 1502.21571934\n",
      " 1515.48165416 1543.79281762 1554.15626764 1553.88096891 1501.9302727\n",
      " 1548.37830014 1507.69911942 1487.38968361 1529.03670163 1543.9071309\n",
      " 1513.03472223 1501.84171001 1537.41306436 1495.91688386 1544.48043868\n",
      " 1516.25971517 1505.32022998 1523.37890356 1502.18965587 1547.80289072\n",
      " 1484.35384121 1546.51536115 1548.77837293 1547.44332107 1519.35993405\n",
      " 1521.30012481 1481.61998676 1497.23078978 1524.85129191 1547.17723163\n",
      " 1506.38333625 1546.92401748 1481.89863862 1544.42433286 1482.77876337\n",
      " 1525.09529677 1540.86122909 1482.01451628 1547.47975682 1545.77319865\n",
      " 1516.57363979 1542.55616348 1514.10462328 1498.4625264  1515.4274256\n",
      " 1539.67053286 1525.5680167  1511.47681145 1543.27413978 1508.22638079\n",
      " 1550.59870714 1548.35777994 1511.12917847 1511.25332678 1527.49501929\n",
      " 1521.58431994 1548.02302225 1527.12163571 1497.23968618 1549.40099177\n",
      " 1510.66535495 1481.087495   1485.78058452 1518.60333186 1465.93130622\n",
      " 1500.21973563 1538.79165962 1509.9274842  1509.18836196 1539.79991157\n",
      " 1478.39499382 1548.29371634 1535.85577933 1537.35664565 1526.32001425\n",
      " 1485.4847656  1525.14858671 1539.83455857 1554.97997369 1525.79883339\n",
      " 1474.34200306 1514.66653164 1532.61822397 1523.83383067 1501.15167444\n",
      " 1549.46045073 1537.13012073 1498.07626753 1479.21199359 1518.11040461\n",
      " 1524.64099541 1486.11073757 1521.79828245 1538.46088082 1542.85658704\n",
      " 1550.80837789 1525.23755078 1523.12139765 1536.33122664 1550.51685073\n",
      " 1551.40524613 1541.93050439 1543.67452545 1507.45846769 1543.86671626\n",
      " 1551.2504297  1538.08781013 1550.0312555  1524.05700247 1513.77813624\n",
      " 1518.97367518 1548.13827416 1551.13057315 1519.4580189  1502.14642534\n",
      " 1546.88874473 1517.37713851 1549.10454709 1482.71961729 1550.4825166\n",
      " 1519.52668714 1546.39487885 1494.16553078 1548.13858704 1547.82099641\n",
      " 1498.09772635 1518.38141158 1510.32170085 1539.09208319 1471.97724042\n",
      " 1496.89938522 1486.57791423 1520.04724224 1548.26734    1482.7361586\n",
      " 1529.23014395 1549.52974472 1515.51755266 1516.26002805 1527.69275336\n",
      " 1519.3540779  1518.90040229 1548.99600145 1511.30326358 1506.68594995\n",
      " 1526.1731556  1534.05565244 1484.2438197  1525.20929717 1489.15851663\n",
      " 1547.94116584 1545.18522681 1547.70543163 1514.38233651 1502.99744636\n",
      " 1551.09257302 1516.86945871 1503.97596884 1483.79716324 1529.59463111\n",
      " 1526.2372192  1527.57812721 1547.92431165 1508.0672726  1518.38141158\n",
      " 1526.84329673 1508.3122161  1527.39787307 1541.19200789 1549.08340114\n",
      " 1511.55866787 1473.92570183 1482.47802693 1484.02431392 1549.23790469\n",
      " 1541.00254447 1503.01063454 1481.44675177 1515.12145876 1550.33628371\n",
      " 1552.49137561 1547.72595182 1482.70642912 1524.52659363 1514.95072678\n",
      " 1467.40548332 1553.68386059 1547.86789295 1531.77212047 1551.14805309\n",
      " 1511.09944899 1512.81248907 1446.03973601 1544.91390697 1542.95529764\n",
      " 1527.99684294 1527.58179322 1548.57540846 1541.05802454 1514.20333388]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(theta, X_1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "L\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    ")\n",
    " : 仮定関数\n",
    "\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの正解値\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）\n",
    "\n",
    "雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "#     mse = ((y_pred - y)**2).sum()/m\n",
    "    mse = ((y_pred - y)**2).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "mse:38341088410.30382\n"
     ]
    }
   ],
   "source": [
    "mse = MSE(y_pred, y_test)\n",
    "# print(\"mse:{}\".format(MSE(y_pred, y_test)))\n",
    "print(type(mse))\n",
    "print(\"mse:{}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19170544205.15191\n"
     ]
    }
   ],
   "source": [
    "# 目的関数実装 20191213\n",
    "#     m = error.shape[0]\n",
    "#     j_theta = (error.sum())**2/2/m\n",
    "objective_func = MSE(y_pred, y_test)/2\n",
    "print(objective_func)\n",
    "# 問６のクラス内に実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.検証\n",
    "### 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "\n",
    "    def __init__(self, num_iter=100, lr=0.000000001, bias=True, verbose=True):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def _linear_hypothesis(self, X): # 問1 \n",
    "        self.h = np.dot(X, self.theta)\n",
    "        return self.h\n",
    "\n",
    "    def _get_error(self, y):\n",
    "        self.error = self.h - np.ravel(y)\n",
    "#         print(\"self.error:{}\".format(self.error))\n",
    "#         print(\"self.h:{}\".format(self.h[:3]))\n",
    "#         print(\"np.ravel(y):{}\".format(np.ravel(y)[:3]))\n",
    "\n",
    "        return self.error\n",
    "\n",
    "    def _gradient_descent(self, X): # 問2 最急降下法\n",
    "        m = X.shape[0] # m はサンプル数の平均を出す時に使うので、Xのレコード数を取得\n",
    "#         print(\"self.theta:{}\".format(self.theta))\n",
    "#         print(\"np.dot(self.error.T, X):{}\".format(np.dot(self.error.T, X)))\n",
    "#         print(\"self.lr:{}\".format(self.lr))\n",
    "#         print(\"m:{}\".format(m))\n",
    "#         print(\"self.error:{}\".format(self.error[:5]))\n",
    "#         print(\"self.lr/m * np.dot(self.error.T, X):{}\".format(self.lr/m * np.dot(self.error.T, X)))\n",
    "# error が大きくなってしまうのでそれを抑える為に self.lrを非常に小さくした所回答に近くなった。\n",
    "        self.theta = self.theta - self.lr/m * np.dot(self.error.T, X)\n",
    "#         print(\"self.theta:{}\".format(self.theta))\n",
    "        return self.theta\n",
    "\n",
    "    def MSE(self, y_pred, y):\n",
    "        m = y.shape[0]\n",
    "    #     mse = ((y_pred - y)**2).sum()/m\n",
    "        self.mse = ((y_pred - y)**2).mean()\n",
    "        return self.mse\n",
    "    \n",
    "    def loss_function(self, error):\n",
    "        m = self.theta.shape[0]\n",
    "        self.j_theta = (self.error**2).mean()/2\n",
    "        return self.j_theta\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # 検証用データの有無を判断する。\n",
    "        self.val_enable = False\n",
    "        if X_val is not None:\n",
    "            self.val_enable = True\n",
    "\n",
    "        # bias（切片）の有無を判定し、有なら切片に影響が出ないように0列目に1を追加する\n",
    "        if self.bias:\n",
    "            X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "            if self.val_enable:\n",
    "                X_val = np.concatenate([np.ones((X_val.shape[0], 1)), X_val], axis=1)\n",
    "\n",
    "        # 適当なthetaを用意する（これを更新して正解に近づけて行くイメージ）\n",
    "        self.theta = np.array([rd.random() for i in range(3)])\n",
    "#         print(\"self.theta:{}\".format(self.theta))\n",
    "\n",
    "        for i in range(self.iter):\n",
    "            # 訓練用データの処理\n",
    "            self._linear_hypothesis(X)# 引数のself は不要\n",
    "            self._get_error(y)\n",
    "            self._gradient_descent(X)\n",
    "#             print(\"self.theta:{}\".format(self.theta))\n",
    "            self.loss_function(self.error) # 最適化されたthetaで目的関数を算出\n",
    "            self.loss[i] = self.j_theta # 問5、目的関数算出\n",
    "            \n",
    "#             # lossを記録 （【問題５】目的関数の実装箇所）\n",
    "#             self.loss[i] = self.MSE(self._linear_hypothesis(X),y)/2\n",
    "            \n",
    "            if self.val_enable:\n",
    "                # 検証用データの処理\n",
    "                self._linear_hypothesis(X_val)# 引数のself は不要\n",
    "                self._get_error(y_val)\n",
    "                self._gradient_descent(X_val)\n",
    "#                 self.loss_function(self.error) # 最適化されたthetaで目的関数を算出           \n",
    "#                 self.val_loss[i] = self.j_theta # 問5、目的関数算出\n",
    "\n",
    "                # lossを記録 （【問題５】目的関数の実装箇所）\n",
    "                self.val_loss[i] = self.MSE(self._linear_hypothesis(X_val),y_val)/2\n",
    "            \n",
    "        if self.verbose:\n",
    "#             print(\"self.loss{}\".format(self.loss))\n",
    "#             print(\"self.val_loss{}\".format(self.val_loss))\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            self.learning_curve()\n",
    "            print()\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        #      切片の確認、学習後に再度実行するので\n",
    "        n_samples = X.shape[0]\n",
    "        if self.bias:\n",
    "            X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "        #(サンプル数 x 特徴量数) @ (特徴量数 x 1) = (サンプル数 x 1)\n",
    "        print(\"Xs:{}\".format(X.shape))\n",
    "        print(\"self.thetas:{}\".format(self.theta.shape))\n",
    "        print(\"X:{}\".format(X))\n",
    "        print(\"self.theta:{}\".format(self.theta))\n",
    "        y_pred = np.dot(X, self.theta)\n",
    "        return y_pred\n",
    "    \n",
    "    def learning_curve(self):\n",
    "        plt.title(\"model loss\")\n",
    "        plt.xlabel(\"iter\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(np.arange(self.iter), self.loss, label=\"train_loss\")\n",
    "        if self.val_enable:\n",
    "            plt.plot(np.arange(self.iter), self.val_loss, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = ScratchLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1064f0198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "slr.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs:(1095, 3)\n",
      "self.thetas:(3,)\n",
      "X:[[1.000e+00 1.504e+03 2.005e+03]\n",
      " [1.000e+00 1.309e+03 1.974e+03]\n",
      " [1.000e+00 1.258e+03 1.939e+03]\n",
      " ...\n",
      " [1.000e+00 8.640e+02 1.955e+03]\n",
      " [1.000e+00 1.426e+03 1.918e+03]\n",
      " [1.000e+00 1.555e+03 2.007e+03]]\n",
      "self.theta:[ 0.16213632 35.3979204  40.13457423]\n",
      "y_pred:[133708.45575213 125561.68947347 122351.68543504 ... 109047.05798635\n",
      " 127455.71000283 135594.01884085]\n"
     ]
    }
   ],
   "source": [
    "y_pred = slr.predict(X_train)\n",
    "print(\"y_pred:{}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  92.19202992 1056.00826855]]\n",
      "[-2040959.50781461]\n",
      "0.647270714473142\n"
     ]
    }
   ],
   "source": [
    "# サイキットラーンを使った線形回帰\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "# 予測モデルを作成\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 回帰係数\n",
    "print(clf.coef_)\n",
    " \n",
    "# 切片 (誤差)\n",
    "print(clf.intercept_)\n",
    " \n",
    "# 決定係数\n",
    "print(clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"linear_hypothesis_list\")\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"theta\")\n",
    "plt.plot(loss_list, color='green', marker='o', linestyle='dashed',\n",
    "         linewidth=1, markersize=2) # 「リスト名」のところに問５のリストの変数名を入れる\n",
    "plt.plot(val_loss, color='red', marker='x', linestyle='dashed',\n",
    "         linewidth=1, markersize=2) # 「リスト名」のところに問５のリストの変数名を入れる\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------以下から動作確認のセル------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # testとtrain分割\n",
    "\n",
    "# データの読み込み\n",
    "# df = pd.read_csv('./train.csv')\n",
    "X = df.loc[:,['GrLivArea','YearBuilt']].values\n",
    "y = df.SalePrice.values\n",
    "\n",
    "# データの前処理\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "# 標準化\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test -X_test.mean()) / X_test.std()\n",
    "y_train_std = (y_train - y_train.mean()) / y_train.std()\n",
    "y_test_std = (y_test - y_test.mean()) / y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def _linear_hypothesis(self,X,coef):\n",
    "        hypothesis = np.dot(X,coef)\n",
    "        return hypothesis\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self,X,coef,error):\n",
    "        coef = coef - self.lr/len(X) * np.dot(error,X)\n",
    "        return coef\n",
    "    \n",
    "    \n",
    "    def MSE(self,y_pred, y):\n",
    "        mse = np.mean((y_pred - y)**2)\n",
    "        return mse\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # trainデータ\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_new = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合はXの０列目に０を挿入する\n",
    "        else:\n",
    "            X_new = np.insert(X, 0, 0, axis=1)\n",
    "\n",
    "        # シータの初期化\n",
    "        self.coef_ = np.random.rand(X_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis = self._linear_hypothesis(X_new,self.coef_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error = hypothesis - y\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_ = self._gradient_descent(X_new,self.coef_,error)\n",
    "            \n",
    "            # lossを記録 （【問題５】目的関数の実装箇所）\n",
    "            self.loss[i] = self.MSE(self._linear_hypothesis(X_new,self.coef_),y)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result = map(str, self.loss)\n",
    "                result = ',\\n'.join(map_result)                \n",
    "                print('Train Data Loss Iteration{0}: \\n{1}'.format(self.iter,result))\n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "        # 検証用データがある場合\n",
    "        if X_val is not None:\n",
    "            #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "            if self.bias is False:\n",
    "                X_val_new = np.insert(X_val, 0, 1, axis=1)\n",
    "            #バイアス項を入れない場合、0を挿入する\n",
    "            else:\n",
    "                X_val_new = np.insert(X_val, 0, 0, axis=1)\n",
    "                \n",
    "        # シータの初期化\n",
    "        self.coef_val_ = np.random.rand(X_val_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis_val = self._linear_hypothesis(X_val_new,self.coef_val_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error_val = hypothesis_val - y_val\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_val_ = self._gradient_descent(X_val_new,self.coef_val_,error_val)\n",
    "            \n",
    "            # lossを記録　 （【問題５】目的関数の実装箇所）\n",
    "            self.val_loss[i] = self.MSE(self._linear_hypothesis(X_val_new,self.coef_val_),y_val)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result_val = map(str, self.val_loss)\n",
    "                result_val = ',\\n'.join(map_result_val)                \n",
    "                print('\\nTest Data Loss Iteration{0}: \\n{1}'.format(self.iter,result_val))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    def predict(self,X):\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_add = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合、0を挿入する\n",
    "        else:\n",
    "            X_add = np.insert(X, 0, 0, axis=1)\n",
    "            \n",
    "        y_pred = np.dot(X_add,self.coef_).reshape(-1,1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化，学習\n",
    "slr=ScratchLinearRegression(num_iter=5000, lr=0.001, bias=False ,verbose=False)\n",
    "slr.fit(X=X_train_std, y=y_train_std, X_val=X_test_std, y_val=y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定\n",
    "y_pred_train = slr.predict(X_train_std)\n",
    "y_pred = slr.predict(X_test_std)\n",
    "print('y_pred:\\n',y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train_MSE：',slr.MSE(y_pred_train,y_train_std))\n",
    "print('Test_MSE：',slr.MSE(y_pred,y_test_std))\n",
    "print('切片：',slr.coef_[0])\n",
    "print('係数：',slr.coef_[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(range(slr.iter)), slr.loss, label=\"loss\")\n",
    "plt.scatter(np.array(range(slr.iter)), slr.val_loss, label=\"val_loss\")\n",
    "\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
